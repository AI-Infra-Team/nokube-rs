{
	"nodes":[
		{"id":"2646f8feb06d5f3b","type":"group","x":-160,"y":360,"width":2820,"height":3400,"label":"集群侧"},
		{"id":"7c01f0b4dd6ebad7","type":"group","x":380,"y":390,"width":2260,"height":3330,"label":"general"},
		{"id":"1992741a2aa2fe3b","type":"group","x":-80,"y":-650,"width":2809,"height":910,"label":"控制侧"},
		{"id":"38790d011e928eb9","type":"group","x":440,"y":2560,"width":2170,"height":1120,"label":"exporter"},
		{"id":"0520f5a5ed0e5699","type":"group","x":2700,"y":260,"width":1380,"height":1465,"label":"监控面板"},
		{"id":"029a051cde4f5915","type":"group","x":-1280,"y":260,"width":820,"height":1630,"label":"集群静态配置+集群actor动态配置"},
		{"id":"689775cc9b14b219","type":"group","x":1880,"y":-597,"width":780,"height":805,"label":"k8s原生命令"},
		{"id":"30cdd7fa9b891781","type":"group","x":-140,"y":390,"width":520,"height":850,"label":"service agent"},
		{"id":"9cf48181aa1561ab","type":"group","x":500,"y":-565,"width":880,"height":402,"label":"new-or-update"},
		{"id":"b1d202983b97c1eb","type":"group","x":660,"y":-960,"width":700,"height":280,"label":"示例"},
		{"id":"8c4790e1a4bce75f","type":"group","x":459,"y":520,"width":346,"height":460,"label":"k8s"},
		{"id":"771931171fc21987","type":"group","x":-5,"y":1380,"width":385,"height":260,"label":"master"},
		{"id":"etcd-storage","type":"text","text":"## etcd 分布式存储\n\n### 数据结构:\n**业务数据:**\n- `/nokube/{cluster}/pods/{name}` - Pod状态\n- `/nokube/{cluster}/events/pod/{name}` - Pod事件\n- `/nokube/{cluster}/deployments/{name}` - Deployment配置\n- `/nokube/{cluster}/daemonsets/{name}` - DaemonSet配置\n- `/nokube/{cluster}/configmaps/{name}` - ConfigMap\n- `/nokube/{cluster}/secrets/{name}` - Secret\n- `cluster/{name}` - 集群元数据\n- `k8s/configmap/{ns}/{name}` - K8s ConfigMap\n- `k8s/secret/{ns}/{name}` - K8s Secret\n\n**Actor存活监控:**\n- `/nokube/{cluster}/actors/{actor-path}/alive` - Actor存活状态\n  - 包含lease_ttl、last_alive时间戳\n  - the_proxy定期更新\n  - 超时标记为Dead\n\n### 写入者:\n- ConfigManager (集群配置)\n- ServiceAgent (Pod状态/事件)\n- K8sStorage (K8s资源)\n- **TheProxy (Actor存活状态)**\n\n### 读取者:\n- ServiceAgent (部署配置)\n- Exporter (集群配置)\n- CLI (Pod状态查询)\n- **TheProxy (Actor存活监控)**","x":-1260,"y":280,"width":680,"height":760},
		{"id":"cluster-config","type":"text","text":"## 集群配置文件\n\n**cluster-config.yaml**\n\n```yaml\ncluster_name: home-cluster\n\nnodes:\n  - ssh_url: \"10.126.126.234:2222\"\n    name: \"pinghu-container\"\n    role: \"head\"\n    workspace: \"/opt/devcon/pa/nokube-workspace\"\n    storage:\n      type: \"local\"\n      path: \"/data/ray/head\"\n    users:\n      - userid: \"pa\"\n        password: \"74123\"\n```\n\n🔧 **Workspace配置来源:**\n1. **集群配置文件** - 每个节点的workspace字段\n2. **代码硬编码** - ServiceAgent中的默认路径\n3. **动态传递** - 通过ClusterConfig传递给Docker操作模块\n\n📂 **实际路径构建:**\n- 基础路径: `{node.workspace}`\n- ConfigMap路径: `{workspace}/configmaps/{deployment-name}`\n- 存储路径: `{workspace}/{storage.path}`","x":-1200,"y":1130,"width":720,"height":740},
		{"id":"config-module","type":"text","text":"## Config 模块\n\n**src/config/**\n- etcd_manager.rs\n- config_manager.rs\n\n🔧 集群配置存储\n📊 节点配置管理","x":-755,"y":-175,"width":260,"height":275},
		{"id":"nokube-config","type":"text","text":"## Nokube 全局配置\n\n路径\n- 用户级: `~/.nokube/config.yaml` (优先)\n- 全局级: `/etc/.nokube/config.yaml`\n- Agent 容器读取: `/etc/.nokube/config.yaml`（部署时将 `{workspace}/config/config.yaml` 挂载）\n\n格式 (YAML)\n```yaml\netcd_endpoints:\n  - 'http://10.0.0.10:2379'\n  - 'http://10.0.0.11:2379'\n```\n⚠️ 端点必须包含 `http://` 或 `https://` 前缀\n\n读取优先级\n1. 用户级 `~/.nokube/config.yaml`\n2. 全局级 `/etc/.nokube/config.yaml`\n\n配置方法\n- 本机创建上述文件并填入 `etcd_endpoints`\n- 部署时，控制器上传到每节点 `{workspace}/config/config.yaml`\n- 启动 Agent 时绑定为容器内 `/etc/.nokube/config.yaml`\n\n部署分布\n- 本地 CLI/控制器: 读取本机配置\n- 远程节点: `{workspace}/config/config.yaml` → 容器 `/etc/.nokube/config.yaml`（供 Agent/TheProxy 访问 etcd）\n- 相关 etcd 存储键：\n  - ClusterMeta: `cluster/{name}`\n  - ClusterConfig: `{cluster_name}`\n  - K8s 对象: `/nokube/{cluster}/(configmaps|secrets|deployments|daemonsets|pods|events/pod)`","x":-1400,"y":-880,"width":560,"height":980},
		{"id":"n-nokube-artifacts","type":"text","text":"## Nokube 打包 (HTTP 分发)\n- 产物目录 (Head 节点): `<workspace>/<mount_subpath>/releases/nokube`\n  - `bin/nokube`\n  - `lib/libcrypto.so.1.1`, `lib/libssl.so.1.1` (可选)\n  - `nokube-image.tar` (可选: 预构建镜像)\n  - `manifest.json`, `install.sh`\n- 生成时机: CLI `new-or-update` 阶段\n- 说明: GitOps Canvas 中 HTTP Server 节点亦有标注","x":-720,"y":-750,"width":520,"height":360},
		{"id":"dashboard-actor","type":"text","text":"## Dashboard: Actor\n\n用途\n- 运行归属视角：按 root_actor 分组查看 pod/container 明细与时序\n- 同时包含 K8s 概览（合并原 Service 视图）\n\n变量\n- cluster: `label_values(nokube_container_cpu_cores, cluster_name)`\n- root_actor: `label_values(..., root_actor)`\n- cpu_axis_max, mem_axis_max: 自动探测上限\n\n面板布局\n- 全局总览（合并自 Service）:\n  - K8s Objects Overview (Namespace/Object/Name/Status/Parent)\n  - Pod–DaemonSet Relationship (status 1/0, stepped)\n  - Container CPU/Memory (%) (stacked)\n  - Service Events Timeline (increase(...[5m]))\n- Root Actors (stat)\n- Container Count ($cluster) (stat)\n- 按 $root_actor 重复分组: \n  - Pods of $root_actor (表: node/pod)\n  - Containers of $root_actor (表: node/pod/container)\n  - Container CPU (cores) [$root_actor] (timeseries)\n  - Container Memory (bytes) [$root_actor] (timeseries)\n\n说明\n- 数据源: `GreptimeDB`","x":3480,"y":335,"width":540,"height":830},
		{"id":"dash-cluster-home","type":"text","text":"## 监控面板规划\n- Cluster Dashboard 设置为默认首页\n- 顶部新增 ‘关键链接’ 面板，提供快捷跳转：\n  - Actor Dashboard (/d/nokube-actor-dashboard)\n  - Logs (MySQL) (/d/nokube-logs-mysql)\n  - HTTP 文件服务器 (Head 节点)\n  - Greptime Metrics (/v1/prometheus)","x":2750,"y":300,"width":580,"height":300},
		{"id":"dash-links-panel","type":"text","text":"### 关键链接面板（Cluster 仪表盘内）\n使用 Text 面板 (markdown) 实现：\n- [Actor Dashboard](/d/nokube-actor-dashboard)\n- [Logs (MySQL)](/d/nokube-logs-mysql)\n- [HTTP 文件服务器](http://<head>:<http_port>)\n- [Greptime Metrics](http://<head>:<greptime_port>/v1/prometheus)","x":2750,"y":640,"width":580,"height":280},
		{"id":"docker-ops-module","type":"text","text":"## 🐳 Docker 操作模块\n\n**src/agent/general/docker_runner.rs**\n\n### 核心功能:\n🏗️ **容器生命周期管理**\n- 创建、启动、停止、删除\n- 健康检查和监控\n- 错误处理和恢复\n\n🗂️ **卷挂载管理**\n- ConfigMap 文件挂载\n- Secret 安全挂载\n- 工作空间目录绑定\n- 权限和安全控制\n\n🌐 **网络和端口**\n- 端口映射和转发\n- 网络模式配置\n- 容器间通信\n\n⚙️ **GitOps ConfigMap 处理**\n```rust\n// 1. 解析YAML内嵌配置\nlet configmap_data = spec.get(\"configMap\")\n  .and_then(|cm| cm.get(\"data\"));\n\n// 2. 创建主机文件系统\nlet config_dir = format!(\n  \"{}/configmaps/{}\", \n  workspace, deployment_name\n);\n\n// 3. 写入配置文件\nfor (filename, content) in configmap_data {\n  let file_path = format!(\n    \"{}/{}\", config_dir, filename\n  );\n  std::fs::write(&file_path, content)?;\n}\n\n// 4. 挂载到容器\nconfig = config.add_volume(\n  config_dir, \n  \"/etc/config\".to_string(), \n  true // read-only\n);\n```\n\n🔒 **安全特性**\n- 输入验证和清理\n- 命令注入防护\n- 权限隔离\n- 资源限制","x":1060,"y":430,"width":520,"height":970},
		{"id":"docker-config-example","type":"text","text":"## ConfigMap 挂载示例\n\n**GitOps YAML结构:**\n```yaml\nspec:\n  configMap:\n    data:\n      requirements.txt: \"flask==2.3.2\\nrequests==2.31.0\"\n      webhook-server.py: \"#!/usr/bin/env python3\\n...\"\n  webhookDeployment:\n    containerSpec:\n      image: python:3.10-slim\n      command: [\"/bin/bash\"]\n      args: [\n        \"-c\", \n        \"pip install -r /etc/config/requirements.txt && python /etc/config/webhook-server.py\"\n      ]\n```\n\n**生成的Docker命令:**\n```bash\ndocker run -d \\\n  --name nokube-pod-{deployment-name} \\\n  -v {workspace}:/pod-workspace \\\n  -v {workspace}/configmaps/{deployment-name}:/etc/config:ro \\\n  -e FLASK_PORT=8080 \\\n  python:3.10-slim \\\n  /bin/bash -c \"pip install -r /etc/config/requirements.txt && python /etc/config/webhook-server.py\"\n```\n\n**文件系统结构:**\n```\n{workspace}/\n├── configmaps/\n│   └── {deployment-name}/\n│       ├── requirements.txt\n│       └── webhook-server.py\n└── ...\n```\n\n**动态变量说明:**\n- `{workspace}` - 工作空间路径 (默认: /opt/devcon/pa/nokube-workspace)\n- `{deployment-name}` - 部署名称 (如: gitops-webhook-server-home-cluster)\n- `{cluster-name}` - 集群名称","x":1590,"y":440,"width":940,"height":880},
		{"id":"63a7919ba26e1c77","type":"text","text":"the_proxy\n特殊actor协程，一个agent一个，用于聚合所有 k8s actor 一段时间内的请求（一般就是校验其从属以及管控的actor是否alive）\n\n以及keepalive","x":480,"y":545,"width":300,"height":195},
		{"id":"9213010bd51b4eba","type":"text","text":"docker启动，稳定隔离运行","x":-100,"y":430,"width":160,"height":90},
		{"id":"dashboard-cluster","type":"text","text":"## Dashboard: Cluster\n\n面板布局\n- Cluster Memory Usage (%)\n- Cluster Container Memory (bytes, stacked) + Used/Total 叠加\n- Network RX/TX (Bytes/s)\n- Cluster Container CPU (%) (stacked)\n- Node Memory Used vs Total (bytes)\n\n说明\n- 数据源: `GreptimeDB`\n- 时间: now-1h, 刷新: 30s\n- 主要维度: instance/node, container","x":2720,"y":335,"width":597,"height":430},
		{"id":"dashboard-logs","type":"text","text":"## Dashboard: Logs (MySQL)\n\n变量\n- container_path: SELECT DISTINCT scope_name AS text FROM opentelemetry_logs WHERE scope_name <> '' ORDER BY text\n\n面板布局\n- Log Messages (Latest):\n\t```\n\tSELECT timestamp AS time, body AS message, severity_text AS level  FROM opentelemetry_logs  WHERE $__timeFilter(timestamp) AND (${container_path:sqlstring} = '' OR scope_name = ${container_path:sqlstring})  ORDER BY timestamp DESC LIMIT 1000\n\t```\n- Log Level Distribution: 按 severity_text 计数 (同样使用 container_path 可选筛选)\n- Logs per Minute: $__timeGroup(timestamp,'1m') + 可选 container_path 筛选\n\n说明\n- 数据源: `greptimemysql` (Greptime MySQL)\n- 日志面板单行展示：隐藏标签、禁用折叠\n- 使用 scope_name 保存容器 Full Path (cluster/root_actor/pod/container)，用于精确筛选","x":2729,"y":805,"width":731,"height":575},
		{"id":"21029617ed1cf87d","type":"text","text":"","x":2720,"y":280,"width":250,"height":4},
		{"id":"remote-control","type":"text","text":"## Remote Control\n\n**src/remote_ctl/**\n- ssh_manager.rs\n- deployment_controller.rs\n\n🔗 SSH 连接管理\n🚀 分布式部署\n\n### 🐳 Docker镜像构建与分发\n**prepare_dependencies()新增功能:**\n1. 构建包含Docker的nokube镜像\n   ```dockerfile\n   FROM ubuntu:22.04\n   RUN apt-get install docker.io python3-pip\n   COPY target/nokube /usr/local/bin/nokube\n   ```\n2. 导出镜像为tar包: `docker save -o nokube-image.tar`\n3. SSH上传tar包到各节点\n4. 远程加载镜像: `docker load -i nokube-image.tar`\n\n**优势:**\n✅ 避免每次容器启动重新下载\n✅ 镜像一次构建，多节点复用\n✅ 离线环境支持\n✅ 网络带宽节省\n\n### 📂 文件上传接口保障\n- 自动创建远程父目录: `mkdir -p <parent>`\n- 自动设置目录归属为当前SSH用户: `chown -R {user}:{user} <dir>`\n- 单文件上传: `upload_file` / `force_upload_file`\n- 目录上传: `upload_directory` (递归处理并统一权限)\n- 调用方无需额外 mkdir/chown，接口已内建","x":-29,"y":-630,"width":510,"height":860},
		{"id":"cli-new-or-update","type":"text","text":"## CLI: new-or-update\n\n用法\n- `nokube new-or-update [config.yaml]`\n\n说明\n- 未提供文件时生成模板 `cluster-config-template.yaml` 并提示二次执行\n- 持久化集群配置到 etcd 并触发部署/更新\n\n示例\n- `nokube new-or-update ./home-cluster.yaml`","x":520,"y":-545,"width":360,"height":362},
		{"id":"k8s-abstraction","type":"text","text":"## K8s 模拟层\nk8s中的daemonset、deployment、pod 统一称作actor，为某个agent里的一个协程所管控\n\n**src/k8s/**\n- objects.rs\n- controllers.rs\n- storage.rs\n- heartbeat.rs\n\n📦 Pod 管理\n⚖️ DaemonSet/Deployment\n🔐 Config/Secret 存储\n💓 生命周期监控","x":-30,"y":790,"width":370,"height":430},
		{"id":"d8d98b5f9f5121be","type":"text","text":"k8s actor \n对应etcd 某个配置\n此外这个actor的alive应该冗余一个key，并且按照这个actor的粒度设置lease\n定期向 the proxy发出请求，保活自己的lease以及检查自己关联组件","x":480,"y":760,"width":300,"height":195},
		{"id":"agent-system","type":"text","text":"## Agent 系统\n\n**src/agent/**\n- general/ 通用功能\n- master_agent/ 主代理\n- service_agent/ 服务代理\n\n🤖 远程命令执行\n📈 监控数据收集\n🐳 容器管理","x":-400,"y":-50,"width":300,"height":300},
		{"id":"cli-monitor","type":"text","text":"## CLI: monitor\n\n用法\n- `nokube monitor --cluster <name>`\n\n说明\n- 启动 GreptimeDB + Grafana，自动配置数据源与仪表盘\n\n示例\n- `nokube monitor --cluster home-cluster`","x":520,"y":-142,"width":360,"height":362},
		{"id":"gitops-extension","type":"text","text":"## GitOps 扩展\n\n**examples/gitops/**\n- 自动化部署\n- 配置同步\n\n🔧 **ConfigMap 挂载支持**\n- YAML内嵌配置文件\n- 自动文件系统映射\n- /etc/config 标准挂载","x":700,"y":-960,"width":230,"height":190},
		{"id":"architecture-principles","type":"text","text":"## 架构原则\n\n### 🔧 最小变更原则\n- 文件分布即模块规划\n- 严格错误处理\n- 无默认值策略\n\n### 🏗️ 容器化运行\n- Service Agent 使用 --pid\n- 观测宿主机信息\n- 统一进程内逻辑\n\n### 📊 监控绑定\n- 集群部署监控\n- 节点 IP 连接\n- 禁用 localhost","x":1070,"y":-920,"width":250,"height":200},
		{"id":"nokube-core","type":"text","text":"# Nokube-rs Core\n\n分布式服务管理器\n- 集群初始化\n- 部署控制\n- 配置管理","x":-400,"y":-275,"width":200,"height":100},
		{"id":"cli-describe","type":"text","text":"## CLI: describe\n\n用法\n- `nokube describe <pod|deployment|daemonset|configmap|secret|service> <name> [-c <name>]`\n\n说明\n- 从 etcd 或内置渲染输出资源详情\n\n示例\n- `nokube describe pod gitops-controller-0 -c home-cluster`","x":1900,"y":-577,"width":360,"height":362},
		{"id":"cli-logs","type":"text","text":"## CLI: logs\n\n用法\n- `nokube logs <pod> [-c <name>] [--follow] [--tail N]`\n\n说明\n- 结合 etcd 状态/事件；Running 时展示示例日志；支持 `--follow`\n\n示例\n- `nokube logs my-pod -c home-cluster --tail 100`","x":1900,"y":-174,"width":360,"height":362},
		{"id":"cli-apply","type":"text","text":"## CLI: apply\n\n用法\n- `nokube apply -f <file> [--cluster <name>] [--dry-run]`\n- `cat manifest.yaml | nokube apply --cluster <name>`\n\n说明\n- 支持多文档 YAML；未指定 `-f` 时从 stdin 读取\n- `--dry-run` 仅解析/打印，不写入 etcd\n\n示例\n- `nokube apply -f gitops.yaml --cluster home-cluster`","x":2280,"y":-577,"width":360,"height":362},
		{"id":"cli-get","type":"text","text":"## CLI: get\n\n用法\n- `nokube get <pods|deployments|daemonsets|configmaps|secrets> [name] [-o table|json|yaml] [-c <name>] [--all-namespaces]`\n\n说明\n- 默认输出 `-o table`；`-c` 等同 `--cluster`\n- services 列表暂未实现\n\n示例\n- `nokube get pods -c home-cluster -o table`","x":2280,"y":-174,"width":360,"height":362},
		{"id":"cli-agent-service","type":"text","text":"## CLI: agent-service\n\n用法\n- `nokube agent-service [--extra-params <BASE64(JSON)>]`\n\n说明\n- 常驻服务模式运行 Agent","x":1450,"y":-168,"width":360,"height":362},
		{"id":"cli-agent-command","type":"text","text":"## CLI: agent-command\n\n用法\n- `nokube agent-command --extra-params <BASE64(JSON)>`\n\n说明\n- 一次性命令模式；`extra-params` 必须包含 `cluster_name`\n\n示例\n- `echo -n '{\"cluster_name\":\"home-cluster\"}' | base64`","x":1450,"y":-571,"width":360,"height":362},
		{"id":"n-distribution-flow","type":"text","text":"## 分发流程 (基于 HTTP)\n1) 本地构建 & 打包\n2) 上传到 Head HTTP 目录\n3) 启动 http.server 容器 (python:3.10-slim)\n4) 节点下载: `http://<head>:<port>/releases/nokube/...`\n   - cmdagent 通过 curl 下载 `bin/`+`lib/` 后执行\n   - service agent 在容器内使用相同来源获取依赖\n5) 不再预分发到各节点 (无 SSH 逐点拷贝)\n","x":920,"y":-540,"width":440,"height":315},
		{"id":"807d8c1bd92464b0","type":"text","text":"## 📝 OTLP 日志收集 (实现同步)\n\n**Endpoint (约定):**\n- OTLP Logs: `http://{head}:{port}/v1/otlp/v1/logs（port 来自 ClusterConfig.monitoring.greptimedb.port）`\n\n**Headers:**\n- `X-Greptime-DB-Name=public`\n- `X-Greptime-Log-Table-Name=opentelemetry_logs`\n- `X-Greptime-Log-Extract-Keys=cluster_name,node_name,source,source_id,container,pod,root_actor,container_path`\n\n**Collector 行为:**\n- 无失败重试，失败仅 error log\n- 外层超时保护（固定 5s）；内部 `force_flush()` 放入 `spawn_blocking`\n- actor 日志设置 `scope_name=container_path` (cluster/root_actor/pod/container)；其他来源使用 `nokube-rs`\n\n**Greptime 表:**\n- 表: `opentelemetry_logs`\n- 列: timestamp, severity_text, body, scope_name, log_attributes(JSON) 等\n\n**Grafana 日志面板:**\n- 数据源: MySQL (greptimemysql)\n- 变量: `container_path`（来自 `scope_name`）\n- SQL 使用 `${container_path:sqlstring}` 可选筛选\n- 日志一行展示（隐藏 Labels/Details）\n\n**Actor 面板联动:**\n- Containers 表的 Container 列跳转到日志面板，链接携带 `var-container_path=<full-path>`","x":1890,"y":2575,"width":700,"height":900},
		{"id":"63020bf5856229b9","type":"text","text":"## Exporter 总览\n\n路径\n- `src/agent/general/exporter.rs`\n\n职责\n- 采集系统与容器指标，推送到 GreptimeDB (Influx 行协议)\n- 按配置轮询 etcd 获取 `ClusterConfig`\n\n推送目标\n- `{greptime}/v1/influxdb/write`（由 head 节点 IP + `monitoring.greptimedb.port` 组装）\n\n周期\n- metrics_interval 默认 30s\n- config_poll_interval 默认 10s\n\n标签增强\n- 容器指标追加 `container_path=cluster/root_actor/pod/container`，与日志 `scope_name` 对齐，便于仪表盘联动\n\n支持\n- Cluster / Actor 仪表盘","x":470,"y":2580,"width":560,"height":640},
		{"id":"exporter-system","type":"text","text":"## Exporter: 系统指标\n\n采集\n- CPU 使用率: `/proc/stat`\n- CPU 逻辑核: `/proc/cpuinfo`（或 `/sys/devices/system/cpu/present` 兜底）\n- 内存占用: `/proc/meminfo` (MemTotal/MemAvailable)\n- 网络流量: `/proc/net/dev`（汇总非 `lo` 接口）\n\n指标名\n- `nokube_cpu_usage`, `nokube_cpu_cores`\n- `nokube_memory_usage`, `nokube_memory_used_bytes`, `nokube_memory_total_bytes`\n- `nokube_network_rx_bytes`, `nokube_network_tx_bytes`\n\n标签\n- `cluster_name`, `node`, `instance`（三者取自节点/集群上下文）","x":1030,"y":2580,"width":820,"height":460},
		{"id":"exporter-containers","type":"text","text":"## Exporter: 容器指标\n\n目标容器\n- 名称以 `nokube-pod-` 开头（`docker ps --format {{.Names}}` 过滤）\n\n采集\n- `docker stats --no-stream --format \"{{.CPUPerc}}\\t{{.MemUsage}}\\t{{.MemPerc}}\"`\n\n指标名\n- `nokube_container_cpu`（容器 CPU%）\n- `nokube_container_cpu_cores`（换算为核: CPU% × 节点逻辑核数）\n- `nokube_container_mem_bytes`, `nokube_container_mem_percent`\n\n标签\n- 基本: `cluster_name`, `node`, `instance`, `container`, `container_name`\n- Pod/Actor 归属: `pod`, `pod_name`, `parent_actor`(pod), `root_actor`, `top_actor`, `upper_actor`, `owner_type`, `canonical=1`\n- 归一化: 由容器名推断 core，`upper_actor = <core>-<cluster>`","x":1030,"y":3080,"width":820,"height":580},
		{"id":"actor-comm","type":"text","text":"## ServiceAgent 间通信\n\n### 首选: etcd 作为控制面总线\n- 事件/信号/心跳均走 etcd 前缀 `/nokube/{cluster}/actors/**`\n- 优点: 去中心、幂等、天然多节点\n\n### 一致性约束\n- 所有操作需幂等，并通过 etcd 可重试","x":1620,"y":1720,"width":560,"height":520},
		{"id":"actor-lifecycle","type":"text","text":"## Actor 协程生命周期与治理\n\n### 角色与路径\n- ServiceAgent: `service/{node}/agent`\n- KubeController: `service/{node}/kubecontroller`\n- DeploymentActor: `service/{node}/deployment/{name}`\n- DaemonSetActor: `service/{node}/daemonset/{name}`\n\n> 统一 ActorPath 便于跨节点协同\n\n### 存活与父子关系\n- 存活键: `/nokube/{cluster}/actors/{actor_path}/alive` (etcd 带租约)\n  - `lease_ttl=15s`, keepalive `5s`\n  - 值包含: `last_alive`, `node`, `version`\n- 父键: `/nokube/{cluster}/actors/{actor_path}/parent` → 父ActorPath\n- 子集合: `/nokube/{cluster}/actors/{actor_path}/children` → 子ActorPath列表\n\n### 子随父灭 (Supervisor)\n- 子协程监听父 `alive`+`drain` 信号；父消失或发出 `shutdown/drain` 时子应优雅退出\n- 超时未退出→ 本地强制 `stop+rm` 容器\n\n### 信号通道\n- `/nokube/{cluster}/actors/{actor_path}/signal`: `shutdown|drain|restart`\n- 由父或控制面写入；子消费后写 `/ack`\n\n### 本地容器命名\n- 统一为 `nokube-pod-{deploymentName}`，便于跨模块回收\n","x":1040,"y":1720,"width":560,"height":520},
		{"id":"orphan-gc","type":"text","text":"## Orphan Reaper（孤儿回收）\n\n触发\n- 每 60s 扫描本机 `nokube-pod-*` 容器\n- 若不存在对应 etcd key（deployments/pods）或父Actor `alive` 缺失→ 标记为孤儿\n\n动作\n- `docker stop && docker rm` 容器\n- 清理 `/pods/{name}` 与 `/events/pod/{name}`\n\n场景\n- 控制面或父Actor崩溃后残留\n- 节点短时网络分区后的自愈","x":420,"y":1720,"width":560,"height":520}
	],
	"edges":[
		{"id":"edge-1","fromNode":"nokube-core","fromSide":"left","toNode":"config-module","toSide":"right","label":"配置读取"},
		{"id":"edge-2","fromNode":"nokube-core","fromSide":"bottom","toNode":"agent-system","toSide":"top","label":"代理管理"},
		{"id":"edge-3","fromNode":"nokube-core","fromSide":"right","toNode":"remote-control","toSide":"left","label":"远程部署"},
		{"id":"edge-5","fromNode":"agent-system","fromSide":"bottom","toNode":"30cdd7fa9b891781","toSide":"left"},
		{"id":"edge-service-etcd","fromNode":"k8s-abstraction","fromSide":"left","toNode":"etcd-storage","toSide":"right","label":"读取配置，部署actor"},
		{"id":"edge-cli-etcd","fromNode":"nokube-core","fromSide":"left","toNode":"etcd-storage","toSide":"right","label":"查询Pod状态"},
		{"id":"edge-docker-ops","fromNode":"30cdd7fa9b891781","fromSide":"right","toNode":"docker-ops-module","toSide":"left","label":"容器管理"},
		{"id":"edge-docker-k8s","fromNode":"k8s-abstraction","fromSide":"right","toNode":"docker-ops-module","toSide":"bottom","label":"Pod容器化"},
		{"id":"edge-docker-example","fromNode":"docker-ops-module","fromSide":"bottom","toNode":"docker-config-example","toSide":"bottom","label":"实现示例"},
		{"id":"edge-config-workspace","fromNode":"cluster-config","fromSide":"right","toNode":"docker-config-example","toSide":"bottom","label":"{workspace}配置来源"},
		{"id":"edge-config-etcd","fromNode":"cluster-config","fromSide":"top","toNode":"etcd-storage","toSide":"bottom","label":"集群配置存储"},
		{"id":"edge-config-docker","fromNode":"cluster-config","fromSide":"right","toNode":"docker-ops-module","toSide":"left","label":"workspace路径"},
		{"id":"03a2ca3d55d61bc6","fromNode":"remote-control","fromSide":"bottom","toNode":"9213010bd51b4eba","toSide":"top"},
		{"id":"151253ad588032ae","fromNode":"config-module","fromSide":"bottom","toNode":"029a051cde4f5915","toSide":"top"},
		{"id":"c7f595250ae29636","fromNode":"nokube-config","fromSide":"right","toNode":"config-module","toSide":"left"}
	]
}
