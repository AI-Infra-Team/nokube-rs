{
	"nodes":[
		{"id":"2646f8feb06d5f3b","type":"group","x":-160,"y":360,"width":2720,"height":2360,"label":"集群侧"},
		{"id":"7c01f0b4dd6ebad7","type":"group","x":420,"y":390,"width":2120,"height":2270,"label":"general"},
		{"id":"1992741a2aa2fe3b","type":"group","x":-80,"y":-650,"width":2180,"height":910,"label":"控制侧"},
		{"id":"0520f5a5ed0e5699","type":"group","x":2620,"y":282,"width":1233,"height":1465,"label":"监控面板"},
		{"id":"029a051cde4f5915","type":"group","x":-1280,"y":260,"width":820,"height":1630,"label":"集群静态配置+集群actor动态配置"},
		{"id":"689775cc9b14b219","type":"group","x":1300,"y":-572,"width":780,"height":805,"label":"k8s原生命令"},
		{"id":"30cdd7fa9b891781","type":"group","x":-140,"y":390,"width":520,"height":850,"label":"service agent"},
		{"id":"b1d202983b97c1eb","type":"group","x":660,"y":-960,"width":700,"height":280,"label":"示例"},
		{"id":"8c4790e1a4bce75f","type":"group","x":459,"y":520,"width":346,"height":460,"label":"k8s"},
		{"id":"771931171fc21987","type":"group","x":-5,"y":1380,"width":385,"height":260,"label":"master"},
		{"id":"agent-system","type":"text","text":"## Agent 系统\n\n**src/agent/**\n- general/ 通用功能\n- master_agent/ 主代理\n- service_agent/ 服务代理\n\n🤖 远程命令执行\n📈 监控数据收集\n🐳 容器管理","x":-400,"y":-50,"width":300,"height":300},
		{"id":"config-module","type":"text","text":"## Config 模块\n\n**src/config/**\n- etcd_manager.rs\n- config_manager.rs\n\n🔧 集群配置存储\n📊 节点配置管理","x":-755,"y":-175,"width":260,"height":275},
		{"id":"nokube-core","type":"text","text":"# Nokube-rs Core\n\n分布式服务管理器\n- 集群初始化\n- 部署控制\n- 配置管理","x":-400,"y":-275,"width":200,"height":100},
		{"id":"k8s-abstraction","type":"text","text":"## K8s 模拟层\nk8s中的daemonset、deployment、pod 统一称作actor，为某个agent里的一个协程所管控\n\n**src/k8s/**\n- objects.rs\n- controllers.rs\n- storage.rs\n- heartbeat.rs\n\n📦 Pod 管理\n⚖️ DaemonSet/Deployment\n🔐 Config/Secret 存储\n💓 生命周期监控","x":-30,"y":790,"width":370,"height":430},
		{"id":"63a7919ba26e1c77","type":"text","text":"the_proxy\n特殊actor协程，一个agent一个，用于聚合所有 k8s actor 一段时间内的请求（一般就是校验其从属以及管控的actor是否alive）\n\n以及keepalive","x":480,"y":545,"width":300,"height":195},
		{"id":"d8d98b5f9f5121be","type":"text","text":"k8s actor \n对应etcd 某个配置\n此外这个actor的alive应该冗余一个key，并且按照这个actor的粒度设置lease\n定期向 the proxy发出请求，保活自己的lease以及检查自己关联组件","x":480,"y":760,"width":300,"height":195},
		{"id":"cli-new-or-update","type":"text","text":"## CLI: new-or-update\n\n用法\n- `nokube new-or-update [config.yaml]`\n\n说明\n- 未提供文件时生成模板 `cluster-config-template.yaml` 并提示二次执行\n- 持久化集群配置到 etcd 并触发部署/更新\n\n示例\n- `nokube new-or-update ./home-cluster.yaml`","x":520,"y":-545,"width":360,"height":362},
		{"id":"cli-monitor","type":"text","text":"## CLI: monitor\n\n用法\n- `nokube monitor --cluster <name>`\n\n说明\n- 启动 GreptimeDB + Grafana，自动配置数据源与仪表盘\n\n示例\n- `nokube monitor --cluster home-cluster`","x":520,"y":-142,"width":360,"height":362},
		{"id":"9213010bd51b4eba","type":"text","text":"docker启动，稳定隔离运行","x":-100,"y":430,"width":160,"height":90},
		{"id":"cli-agent-command","type":"text","text":"## CLI: agent-command\n\n用法\n- `nokube agent-command --extra-params <BASE64(JSON)>`\n\n说明\n- 一次性命令模式；`extra-params` 必须包含 `cluster_name`\n\n示例\n- `echo -n '{\"cluster_name\":\"home-cluster\"}' | base64`","x":920,"y":-545,"width":360,"height":362},
		{"id":"cli-agent-service","type":"text","text":"## CLI: agent-service\n\n用法\n- `nokube agent-service [--extra-params <BASE64(JSON)>]`\n\n说明\n- 常驻服务模式运行 Agent","x":920,"y":-142,"width":360,"height":362},
		{"id":"cli-logs","type":"text","text":"## CLI: logs\n\n用法\n- `nokube logs <pod> [-c <name>] [--follow] [--tail N]`\n\n说明\n- 结合 etcd 状态/事件；Running 时展示示例日志；支持 `--follow`\n\n示例\n- `nokube logs my-pod -c home-cluster --tail 100`","x":1320,"y":-149,"width":360,"height":362},
		{"id":"cli-get","type":"text","text":"## CLI: get\n\n用法\n- `nokube get <pods|deployments|daemonsets|configmaps|secrets> [name] [-o table|json|yaml] [-c <name>] [--all-namespaces]`\n\n说明\n- 默认输出 `-o table`；`-c` 等同 `--cluster`\n- services 列表暂未实现\n\n示例\n- `nokube get pods -c home-cluster -o table`","x":1700,"y":-149,"width":360,"height":362},
		{"id":"cli-apply","type":"text","text":"## CLI: apply\n\n用法\n- `nokube apply -f <file> [--cluster <name>] [--dry-run]`\n- `cat manifest.yaml | nokube apply --cluster <name>`\n\n说明\n- 支持多文档 YAML；未指定 `-f` 时从 stdin 读取\n- `--dry-run` 仅解析/打印，不写入 etcd\n\n示例\n- `nokube apply -f gitops.yaml --cluster home-cluster`","x":1700,"y":-552,"width":360,"height":362},
		{"id":"cli-describe","type":"text","text":"## CLI: describe\n\n用法\n- `nokube describe <pod|deployment|daemonset|configmap|secret|service> <name> [-c <name>]`\n\n说明\n- 从 etcd 或内置渲染输出资源详情\n\n示例\n- `nokube describe pod gitops-controller-0 -c home-cluster`","x":1320,"y":-552,"width":360,"height":362},
		{"id":"remote-control","type":"text","text":"## Remote Control\n\n**src/remote_ctl/**\n- ssh_manager.rs\n- deployment_controller.rs\n\n🔗 SSH 连接管理\n🚀 分布式部署\n\n### 🐳 Docker镜像构建与分发\n**prepare_dependencies()新增功能:**\n1. 构建包含Docker的nokube镜像\n   ```dockerfile\n   FROM ubuntu:22.04\n   RUN apt-get install docker.io python3-pip\n   COPY target/nokube /usr/local/bin/nokube\n   ```\n2. 导出镜像为tar包: `docker save -o nokube-image.tar`\n3. SSH上传tar包到各节点\n4. 远程加载镜像: `docker load -i nokube-image.tar`\n\n**优势:**\n✅ 避免每次容器启动重新下载\n✅ 镜像一次构建，多节点复用\n✅ 离线环境支持\n✅ 网络带宽节省\n\n### 📂 文件上传接口保障\n- 自动创建远程父目录: `mkdir -p <parent>`\n- 自动设置目录归属为当前SSH用户: `chown -R {user}:{user} <dir>`\n- 单文件上传: `upload_file` / `force_upload_file`\n- 目录上传: `upload_directory` (递归处理并统一权限)\n- 调用方无需额外 mkdir/chown，接口已内建","x":-29,"y":-630,"width":510,"height":860},
		{"id":"gitops-extension","type":"text","text":"## GitOps 扩展\n\n**examples/gitops/**\n- 自动化部署\n- Webhook 集成\n- 配置同步\n\n🔧 **ConfigMap 挂载支持**\n- YAML内嵌配置文件\n- 自动文件系统映射\n- /etc/config 标准挂载","x":700,"y":-960,"width":230,"height":190},
		{"id":"architecture-principles","type":"text","text":"## 架构原则\n\n### 🔧 最小变更原则\n- 文件分布即模块规划\n- 严格错误处理\n- 无默认值策略\n\n### 🏗️ 容器化运行\n- Service Agent 使用 --pid\n- 观测宿主机信息\n- 统一进程内逻辑\n\n### 📊 监控绑定\n- 集群部署监控\n- 节点 IP 连接\n- 禁用 localhost","x":1070,"y":-920,"width":250,"height":200},
		{"id":"etcd-storage","type":"text","text":"## etcd 分布式存储\n\n### 数据结构:\n**业务数据:**\n- `/nokube/{cluster}/pods/{name}` - Pod状态\n- `/nokube/{cluster}/events/pod/{name}` - Pod事件\n- `/nokube/{cluster}/deployments/{name}` - Deployment配置\n- `/nokube/{cluster}/daemonsets/{name}` - DaemonSet配置\n- `/nokube/{cluster}/configmaps/{name}` - ConfigMap\n- `/nokube/{cluster}/secrets/{name}` - Secret\n- `cluster/{name}` - 集群元数据\n- `k8s/configmap/{ns}/{name}` - K8s ConfigMap\n- `k8s/secret/{ns}/{name}` - K8s Secret\n\n**Actor存活监控:**\n- `/nokube/{cluster}/actors/{actor-path}/alive` - Actor存活状态\n  - 包含lease_ttl、last_alive时间戳\n  - the_proxy定期更新\n  - 超时标记为Dead\n\n### 写入者:\n- ConfigManager (集群配置)\n- ServiceAgent (Pod状态/事件)\n- K8sStorage (K8s资源)\n- **TheProxy (Actor存活状态)**\n\n### 读取者:\n- ServiceAgent (部署配置)\n- Exporter (集群配置)\n- CLI (Pod状态查询)\n- **TheProxy (Actor存活监控)**","x":-1260,"y":280,"width":680,"height":760},
		{"id":"cluster-config","type":"text","text":"## 集群配置文件\n\n**cluster-config.yaml**\n\n```yaml\ncluster_name: home-cluster\n\nnodes:\n  - ssh_url: \"10.126.126.234:2222\"\n    name: \"pinghu-container\"\n    role: \"head\"\n    workspace: \"/opt/devcon/pa/nokube-workspace\"\n    storage:\n      type: \"local\"\n      path: \"/data/ray/head\"\n    users:\n      - userid: \"pa\"\n        password: \"74123\"\n```\n\n🔧 **Workspace配置来源:**\n1. **集群配置文件** - 每个节点的workspace字段\n2. **代码硬编码** - ServiceAgent中的默认路径\n3. **动态传递** - 通过ClusterConfig传递给Docker操作模块\n\n📂 **实际路径构建:**\n- 基础路径: `{node.workspace}`\n- ConfigMap路径: `{workspace}/configmaps/{deployment-name}`\n- 存储路径: `{workspace}/{storage.path}`","x":-1200,"y":1130,"width":720,"height":740},
		{"id":"nokube-config","type":"text","text":"## Nokube 全局配置\n\n路径\n- 用户级: `~/.nokube/config.yaml` (优先)\n- 全局级: `/etc/.nokube/config.yaml`\n- Agent 容器读取: `/etc/.nokube/config.yaml`（部署时将 `{workspace}/config/config.yaml` 挂载）\n\n格式 (YAML)\n```yaml\netcd_endpoints:\n  - 'http://10.0.0.10:2379'\n  - 'http://10.0.0.11:2379'\n```\n⚠️ 端点必须包含 `http://` 或 `https://` 前缀\n\n读取优先级\n1. 用户级 `~/.nokube/config.yaml`\n2. 全局级 `/etc/.nokube/config.yaml`\n\n配置方法\n- 本机创建上述文件并填入 `etcd_endpoints`\n- 部署时，控制器上传到每节点 `{workspace}/config/config.yaml`\n- 启动 Agent 时绑定为容器内 `/etc/.nokube/config.yaml`\n\n部署分布\n- 本地 CLI/控制器: 读取本机配置\n- 远程节点: `{workspace}/config/config.yaml` → 容器 `/etc/.nokube/config.yaml`（供 Agent/TheProxy 访问 etcd）\n- 相关 etcd 存储键：\n  - ClusterMeta: `cluster/{name}`\n  - ClusterConfig: `{cluster_name}`\n  - K8s 对象: `/nokube/{cluster}/(configmaps|secrets|deployments|daemonsets|pods|events/pod)`","x":-1400,"y":-880,"width":560,"height":980},
		{"id":"dashboard-actor","type":"text","text":"## Dashboard: Actor\n\n用途\n- 运行归属视角：按 root_actor 分组查看 pod/container 明细与时序\n- 同时包含 K8s 概览（合并原 Service 视图）\n\n变量\n- cluster: `label_values(nokube_container_cpu_cores, cluster_name)`\n- root_actor: `label_values(..., root_actor)`\n- cpu_axis_max, mem_axis_max: 自动探测上限\n\n面板布局\n- 全局总览（合并自 Service）:\n  - K8s Objects Overview (Namespace/Object/Name/Status/Parent)\n  - Pod–DaemonSet Relationship (status 1/0, stepped)\n  - Container CPU/Memory (%) (stacked)\n  - Service Events Timeline (increase(...[5m]))\n- Root Actors (stat)\n- Container Count ($cluster) (stat)\n- 按 $root_actor 重复分组: \n  - Pods of $root_actor (表: node/pod)\n  - Containers of $root_actor (表: node/pod/container)\n  - Container CPU (cores) [$root_actor] (timeseries)\n  - Container Memory (bytes) [$root_actor] (timeseries)\n\n说明\n- 数据源: `GreptimeDB`","x":3273,"y":357,"width":540,"height":830},
		{"id":"dashboard-cluster","type":"text","text":"## Dashboard: Cluster\n\n面板布局\n- Cluster Memory Usage (%)\n- Cluster Container Memory (bytes, stacked) + Used/Total 叠加\n- Network RX/TX (Bytes/s)\n- Cluster Container CPU (%) (stacked)\n- Node Memory Used vs Total (bytes)\n\n说明\n- 数据源: `GreptimeDB`\n- 时间: now-1h, 刷新: 30s\n- 主要维度: instance/node, container","x":2640,"y":357,"width":597,"height":430},
		{"id":"dashboard-logs","type":"text","text":"## Dashboard: Logs (OTLP)\n\n变量\n- cluster/source/source_id: GreptimeSQL 查询 DISTINCT\n- level: custom( All/ERROR/WARN/INFO/DEBUG )\n\n面板布局\n- Log Level Distribution (饼图)\n- Logs per Source (rate) (时序)\n- Recent Logs Timeline (时序)\n- Log Messages (Latest 100) (表: 时间,级别,集群,节点,来源,消息)\n\n说明\n- 数据源: `GreptimeSQL` (Postgres)\n- 基于 `opentelemetry_logs` 表聚合查询","x":2649,"y":827,"width":580,"height":460},
		{"id":"21029617ed1cf87d","type":"text","text":"","x":2640,"y":302,"width":250,"height":4},
		{"id":"docker-config-example","type":"text","text":"## ConfigMap 挂载示例\n\n**GitOps YAML结构:**\n```yaml\nspec:\n  configMap:\n    data:\n      requirements.txt: \"flask==2.3.2\\nrequests==2.31.0\"\n      webhook-server.py: \"#!/usr/bin/env python3\\n...\"\n  webhookDeployment:\n    containerSpec:\n      image: python:3.10-slim\n      command: [\"/bin/bash\"]\n      args: [\n        \"-c\", \n        \"pip install -r /etc/config/requirements.txt && python /etc/config/webhook-server.py\"\n      ]\n```\n\n**生成的Docker命令:**\n```bash\ndocker run -d \\\n  --name nokube-pod-{deployment-name} \\\n  -v {workspace}:/pod-workspace \\\n  -v {workspace}/configmaps/{deployment-name}:/etc/config:ro \\\n  -e FLASK_PORT=8080 \\\n  python:3.10-slim \\\n  /bin/bash -c \"pip install -r /etc/config/requirements.txt && python /etc/config/webhook-server.py\"\n```\n\n**文件系统结构:**\n```\n{workspace}/\n├── configmaps/\n│   └── {deployment-name}/\n│       ├── requirements.txt\n│       └── webhook-server.py\n└── ...\n```\n\n**动态变量说明:**\n- `{workspace}` - 工作空间路径 (默认: /opt/devcon/pa/nokube-workspace)\n- `{deployment-name}` - 部署名称 (如: gitops-webhook-server-home-cluster)\n- `{cluster-name}` - 集群名称","x":1590,"y":440,"width":940,"height":880},
		{"id":"docker-ops-module","type":"text","text":"## 🐳 Docker 操作模块\n\n**src/agent/general/docker_runner.rs**\n\n### 核心功能:\n🏗️ **容器生命周期管理**\n- 创建、启动、停止、删除\n- 健康检查和监控\n- 错误处理和恢复\n\n🗂️ **卷挂载管理**\n- ConfigMap 文件挂载\n- Secret 安全挂载\n- 工作空间目录绑定\n- 权限和安全控制\n\n🌐 **网络和端口**\n- 端口映射和转发\n- 网络模式配置\n- 容器间通信\n\n⚙️ **GitOps ConfigMap 处理**\n```rust\n// 1. 解析YAML内嵌配置\nlet configmap_data = spec.get(\"configMap\")\n  .and_then(|cm| cm.get(\"data\"));\n\n// 2. 创建主机文件系统\nlet config_dir = format!(\n  \"{}/configmaps/{}\", \n  workspace, deployment_name\n);\n\n// 3. 写入配置文件\nfor (filename, content) in configmap_data {\n  let file_path = format!(\n    \"{}/{}\", config_dir, filename\n  );\n  std::fs::write(&file_path, content)?;\n}\n\n// 4. 挂载到容器\nconfig = config.add_volume(\n  config_dir, \n  \"/etc/config\".to_string(), \n  true // read-only\n);\n```\n\n🔒 **安全特性**\n- 输入验证和清理\n- 命令注入防护\n- 权限隔离\n- 资源限制","x":1060,"y":430,"width":520,"height":970},
		{"id":"63020bf5856229b9","type":"text","text":"## Exporter 总览\n\n路径\n- `src/agent/general/exporter.rs`\n\n职责\n- 采集系统与容器指标，推送到 GreptimeDB (Influx 行协议)\n- 按配置轮询 etcd 获取 `ClusterConfig`\n\n推送目标\n- `{greptime}/v1/influxdb/write`（由 head 节点 IP + `monitoring.greptimedb.port` 组装）\n\n周期\n- metrics_interval 默认 30s\n- config_poll_interval 默认 10s\n\n支持\n- Cluster / Actor 仪表盘","x":480,"y":1520,"width":500,"height":580},
		{"id":"exporter-system","type":"text","text":"## Exporter: 系统指标\n\n采集\n- CPU 使用率: `/proc/stat`\n- CPU 逻辑核: `/proc/cpuinfo`（或 `/sys/devices/system/cpu/present` 兜底）\n- 内存占用: `/proc/meminfo` (MemTotal/MemAvailable)\n- 网络流量: `/proc/net/dev`（汇总非 `lo` 接口）\n\n指标名\n- `nokube_cpu_usage`, `nokube_cpu_cores`\n- `nokube_memory_usage`, `nokube_memory_used_bytes`, `nokube_memory_total_bytes`\n- `nokube_network_rx_bytes`, `nokube_network_tx_bytes`\n\n标签\n- `cluster_name`, `node`, `instance`（三者取自节点/集群上下文）","x":1040,"y":1520,"width":820,"height":460},
		{"id":"exporter-containers","type":"text","text":"## Exporter: 容器指标\n\n目标容器\n- 名称以 `nokube-pod-` 开头（`docker ps --format {{.Names}}` 过滤）\n\n采集\n- `docker stats --no-stream --format \"{{.CPUPerc}}\\t{{.MemUsage}}\\t{{.MemPerc}}\"`\n\n指标名\n- `nokube_container_cpu`（容器 CPU%）\n- `nokube_container_cpu_cores`（换算为核: CPU% × 节点逻辑核数）\n- `nokube_container_mem_bytes`, `nokube_container_mem_percent`\n\n标签\n- 基本: `cluster_name`, `node`, `instance`, `container`, `container_name`\n- Pod/Actor 归属: `pod`, `pod_name`, `parent_actor`(pod), `root_actor`, `top_actor`, `upper_actor`, `owner_type`, `canonical=1`\n- 归一化: 由容器名推断 core，`upper_actor = <core>-<cluster>`","x":1040,"y":2020,"width":820,"height":580},
		{"id":"807d8c1bd92464b0","type":"text","text":"## 📝 OTLP日志收集\n\n**完全符合OpenTelemetry规范:**\n- OTLP API: `http://{host}:4000/v1/otlp/v1/logs`\n- Headers: `X-Greptime-DB-Name: logs`, `X-Greptime-Log-Table-Name: nokube_logs`\n- 提取字段: `X-Greptime-Log-Extract-Keys: cluster_name,node_name,source,source_id`\n\n**数据结构:**\n- ResourceLogs → ScopeLogs → LogRecords\n- 时间戳: `timeUnixNano` (纳秒精度)\n- 严重性: `severityText` + `severityNumber`\n- 消息体: `body.stringValue`\n- 属性: `attributes[]` 数组\n\n**GreptimeDB表结构:**\n- `opentelemetry_logs` (默认OTLP表)\n- timestamp(时间索引), severity_text, body, log_attributes(JSON)\n\n**日志来源:**\n- grafana服务、service agent、所有pod的docker进程\n\n**Grafana面板:**\n- 日志级别分布 (饼图)\n- 按来源的日志率 (时序图)\n- 最新日志时间线 (时序图)\n- 日志消息表 (表格，最新100条)","x":1900,"y":1515,"width":570,"height":795}
	],
	"edges":[
		{"id":"edge-1","fromNode":"nokube-core","fromSide":"left","toNode":"config-module","toSide":"right","label":"配置读取"},
		{"id":"edge-2","fromNode":"nokube-core","fromSide":"bottom","toNode":"agent-system","toSide":"top","label":"代理管理"},
		{"id":"edge-3","fromNode":"nokube-core","fromSide":"right","toNode":"remote-control","toSide":"left","label":"远程部署"},
		{"id":"edge-5","fromNode":"agent-system","fromSide":"bottom","toNode":"30cdd7fa9b891781","toSide":"left"},
		{"id":"edge-service-etcd","fromNode":"k8s-abstraction","fromSide":"left","toNode":"etcd-storage","toSide":"right","label":"读取配置，部署actor"},
		{"id":"edge-cli-etcd","fromNode":"nokube-core","fromSide":"left","toNode":"etcd-storage","toSide":"right","label":"查询Pod状态"},
		{"id":"edge-docker-ops","fromNode":"30cdd7fa9b891781","fromSide":"right","toNode":"docker-ops-module","toSide":"left","label":"容器管理"},
		{"id":"edge-docker-k8s","fromNode":"k8s-abstraction","fromSide":"right","toNode":"docker-ops-module","toSide":"bottom","label":"Pod容器化"},
		{"id":"edge-docker-example","fromNode":"docker-ops-module","fromSide":"bottom","toNode":"docker-config-example","toSide":"bottom","label":"实现示例"},
		{"id":"edge-config-workspace","fromNode":"cluster-config","fromSide":"right","toNode":"docker-config-example","toSide":"bottom","label":"{workspace}配置来源"},
		{"id":"edge-config-etcd","fromNode":"cluster-config","fromSide":"top","toNode":"etcd-storage","toSide":"bottom","label":"集群配置存储"},
		{"id":"edge-config-docker","fromNode":"cluster-config","fromSide":"right","toNode":"docker-ops-module","toSide":"left","label":"workspace路径"},
		{"id":"03a2ca3d55d61bc6","fromNode":"remote-control","fromSide":"bottom","toNode":"9213010bd51b4eba","toSide":"top"},
		{"id":"151253ad588032ae","fromNode":"config-module","fromSide":"bottom","toNode":"029a051cde4f5915","toSide":"top"},
		{"id":"c7f595250ae29636","fromNode":"nokube-config","fromSide":"right","toNode":"config-module","toSide":"left"}
	]
}