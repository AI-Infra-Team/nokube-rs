{
	"nodes":[
		{"id":"2646f8feb06d5f3b","type":"group","x":-160,"y":360,"width":5840,"height":5880,"label":"集群侧"},
		{"id":"0520f5a5ed0e5699","type":"group","x":5760,"y":1680,"width":4900,"height":4480,"label":"监控面板"},
		{"id":"7c01f0b4dd6ebad7","type":"group","x":2590,"y":390,"width":3050,"height":5770,"label":"general"},
		{"id":"30cdd7fa9b891781","type":"group","x":-140,"y":390,"width":2700,"height":5050,"label":"service agent"},
		{"id":"8c4790e1a4bce75f","type":"group","x":-80,"y":1660,"width":2600,"height":3610,"label":"k8s"},
		{"id":"e758f2cb9e2eb39b","type":"group","x":-28,"y":1720,"width":2495,"height":2968,"label":"k8s actor"},
		{"id":"38790d011e928eb9","type":"group","x":2660,"y":4480,"width":2820,"height":1580,"label":"exporter"},
		{"id":"1992741a2aa2fe3b","type":"group","x":-80,"y":-650,"width":2809,"height":910,"label":"控制侧"},
		{"id":"73ab2ea86cf166dd","type":"group","x":7900,"y":4000,"width":950,"height":1670,"label":"指标集合"},
		{"id":"28016ccabe95653d","type":"group","x":3880,"y":4520,"width":1520,"height":940,"label":"log"},
		{"id":"1c575d5d7c0f1487","type":"group","x":9048,"y":3240,"width":1025,"height":1380,"label":"Actor Dashboard Panels"},
		{"id":"029a051cde4f5915","type":"group","x":-1280,"y":260,"width":820,"height":1630,"label":"集群静态配置+集群actor动态配置"},
		{"id":"1ef7b6b5a7e6c3c9","type":"group","x":8980,"y":4760,"width":1160,"height":1060,"label":"Cluster Dashboard Panels"},
		{"id":"fb1e32101b879bee","type":"group","x":6880,"y":3680,"width":800,"height":1030,"label":"dashboard配置变量"},
		{"id":"689775cc9b14b219","type":"group","x":1880,"y":-597,"width":780,"height":805,"label":"k8s原生命令"},
		{"id":"9cf48181aa1561ab","type":"group","x":500,"y":-565,"width":880,"height":402,"label":"new-or-update"},
		{"id":"b1d202983b97c1eb","type":"group","x":660,"y":-960,"width":700,"height":280,"label":"示例"},
		{"id":"logcollector-kubecontroller-link","type":"text","text":"## LogCollector ↔ KubeController 协同\n\n- 订阅方式：通过 `register_container_listener` 挂到统一容器事件总线\n- 事件处理：\n  - create → 下发 `FollowContainer`，并补上历史日志回溯\n  - stop → 下发 `StopContainer`，并触发 flush\n- 注册流程：握手后立即遍历现有容器（防止启动缺口）","x":4520,"y":3805,"width":820,"height":615},
		{"id":"807d8c1bd92464b0","type":"text","text":"## 📝 OTLP 日志收集 (实现同步)\n\n**Endpoint (约定):**\n- OTLP Logs: `http://{head}:{port}/v1/otlp/v1/logs（port 来自 ClusterConfig.monitoring.greptimedb.port）`\n\n**Headers:**\n- `X-Greptime-DB-Name=public`\n- `X-Greptime-Log-Table-Name=opentelemetry_logs`\n- `X-Greptime-Log-Extract-Keys=cluster_name,node_name,source,source_id,container,pod,root_actor,container_path`\n\n**Collector 行为:**\n- 无失败重试，失败仅 error log\n- 外层超时保护（固定 5s）；内部 `force_flush()` 放入 `spawn_blocking`\n- actor 日志设置 `scope_name=container_path` (cluster/root_actor/pod/container)；其他来源使用 `nokube-rs`\n\n**Greptime 表:**\n- 表: `opentelemetry_logs`\n- 列: timestamp, severity_text, body, scope_name, log_attributes(JSON) 等\n\n**Grafana 日志面板:**\n- 数据源: MySQL (greptimemysql)\n- 变量: `fullpath`（来自 `scope_name`，兼容 legacy `container_path`）\n- SQL 使用 `COALESCE(${fullpath:sqlstring}, ${container_path:sqlstring})` 可选筛选\n- 日志一行展示（隐藏 Labels/Details）\n\n**Actor 面板联动:**\n- Containers 表的 Container 列跳转到日志面板，链接携带 `var-fullpath=<full-path>`（同时保留 legacy `var-container_path`）","x":3900,"y":4540,"width":700,"height":900},
		{"id":"log-collector-overview","type":"text","text":"## LogCollector 架构\n\n位置\n- 模块: `src/agent/general/log_collector.rs`，由 ServiceModeAgent 初始化。\n\n职责\n- 通过 `docker logs -f` 跟随 `nokube-grafana`、`nokube-greptimedb` 与全部 `nokube-pod-*` 容器输出\n- 对 actor 容器推导 `cluster/root_actor/pod/container`，写入 `container_path` 与 OTLP scope_name\n- 维护 mpsc 命令通道，根据 Follow/Stop 指令增删容器跟随任务\n- 以 5s 周期批量推送 OTLP Logs 至 GreptimeDB HTTP，支持 Basic Auth\n\n协作说明\n- 与 KubeController 的协作详见 “LogCollector ↔ KubeController 协同”。\n\n日志拉取策略\n- 使用 `docker logs -f --tail 10`，首次仅回放近 10 条，后续持续 follow，确保增量消费。\n- 子进程退出后每隔 5s 重连，容器重启也能继续衔接，避免重复。\n- stdout/stderr 分流逐行写入，无本地落盘，直接发送到 OTLP。\n- 内部封装在 `tokio::spawn` 的无限循环中，`docker logs -f` 结束后 `wait` + 5s 退避再重启子进程，确保持续 follow。","x":4660,"y":4540,"width":720,"height":800},
		{"id":"actor-comm","type":"text","text":"## ServiceAgent 间通信\n\n### 首选: etcd 作为控制面总线\n- 事件/信号/心跳均走 etcd 前缀 `/nokube/{cluster}/actors/**`\n- 优点: 去中心、幂等、天然多节点\n\n### 一致性约束\n- 所有操作需幂等，并通过 etcd 可重试","x":4920,"y":2480,"width":560,"height":520},
		{"id":"dashboard-logs","type":"text","text":"## Dashboard: Logs (MySQL)\n\n变量\n- container_path: SELECT DISTINCT scope_name AS text FROM opentelemetry_logs WHERE scope_name <> '' ORDER BY text\n\n面板布局\n- Log Messages (Latest):\n\t```\n\tSELECT timestamp AS time, body AS message, severity_text AS level  FROM opentelemetry_logs  WHERE $__timeFilter(timestamp) AND (${container_path:sqlstring} = '' OR scope_name = ${container_path:sqlstring})  ORDER BY timestamp DESC LIMIT 1000\n\t```\n- Log error & warning\n- Log Level Distribution: 按 severity_text 计数 (同样使用 container_path 可选筛选) | Logs per Minute: $__timeGroup(timestamp,'1m') + 可选 container_path 筛选\n\n说明\n- 数据源: `greptimemysql` (Greptime MySQL)\n- 日志面板单行展示：隐藏标签、禁用折叠\n- 使用 scope_name 保存容器 Full Path (cluster/root_actor/pod/container)，用于精确筛选","x":5810,"y":2425,"width":731,"height":575},
		{"id":"block-exporter-vs-kube","type":"text","text":"## Exporter ⇆ KubeController\n- **责任边界**：KubeController 读写 etcd、生成容器(`nokube-pod-*`)，通过 `DockerRunner` 控制生命周期；Exporter 只读 Docker 运行时和系统 /proc，向 GreptimeDB 推送节点+容器指标。\n- **事件监听**：Exporter 通过 `register_container_listener` 订阅统一容器事件总线（create/stop），注册后立即执行一次全集抓取，避免启动窗口遗漏。\n- **数据流**：etcd 中的 actor 配置 → KubeController 拉起/回收容器（广播事件）→ Exporter 接收事件并校准采集 → GreptimeDB/Grafana 展示。\n- **退出联动**：一旦收到 stop 事件或轮询确认容器不再存在，Exporter 会写出一次 `nokube_actor_status{actor_level=\"pod\"}=-1`（CPU/内存置零）并从 tracker 移除该容器，Grafana 依靠 `status > 0` 过滤即可在当前采样周期内下架该容器。","x":3020,"y":4000,"width":900,"height":380},
		{"id":"exporter-config-task","type":"text","text":"## Exporter 配置轮询 [独立task]\n归属: Exporter\n触发: tokio::spawn (start_config_polling)\n周期: `config_poll_interval` 秒 (默认 10s)\n职责: 读取 `/cluster/{name}` 与 ClusterConfig, 刷新 current_config\n关键代码: src/agent/general/exporter.rs::start_config_polling","x":3270,"y":4585,"width":560,"height":320},
		{"id":"exporter-metrics-task","type":"text","text":"## Exporter 指标采集 [独立task]\n归属: Exporter\n触发: tokio::spawn (start_metrics_collection)\n周期: `metrics_interval` 秒 (默认 30s)\n职责: 聚合系统/容器指标并推送至 GreptimeDB Influx API\n关键代码: src/agent/general/exporter.rs::start_metrics_collection","x":3270,"y":4925,"width":560,"height":320},
        {"id":"dashboard-actor","type":"text","text":"## Dashboard: Actor\n\n用途\n- 运行归属视角：按 root_actor 分组查看 pod/container 明细与时序\n- 同时包含 Actor 概览（合并原 Service 视图）\n\n变量\n- cluster: `label_values(nokube_container_cpu_cores, cluster_name)`\n- root_actor: `query_result(last_over_time(nokube_actor_status{cluster_name=~\"$cluster\", actor_level=\"root\", canonical=\"1\"}[30s]) > 0)`（Root actor 心跳；仅保留近 30s 存活的 root_actor）\n- container: `query_result(last_over_time(nokube_actor_status{cluster_name=~\"$cluster\", actor_level=\"pod\", root_actor=~\"$root_actor\", canonical=\"1\"}[30s]) > 0)`（Pod/容器所属 actor 心跳；与 root_actor 同步窗口）\n- node: `query_result(last_over_time(nokube_actor_status{cluster_name=~\"$cluster\", actor_level=\"pod\", root_actor=~\"$root_actor\", container=~\"$container\", canonical=\"1\"}[30s]) > 0)`（节点筛选，受 root_actor/container 约束）\n- cpu_axis_max, mem_axis_max: 自动探测上限\n\n隐藏过滤变量（constant, hidden，仅用于查询复用）\n- cluster_filter = `${cluster:regex}`\n- root_actor_filter = `${root_actor:regex}`\n- container_filter = `${container:regex}`\n- node_filter = `${node:regex}`\n\n面板布局\n- 全局总览（合并自 Service）：\n  - Actors Overview (Namespace/Actor/Name/Status/Parent)\n  - Pod–DaemonSet Relationship (status 1/0, stepped)\n  - Container CPU/Memory (%) (stacked)\n  - Service Events Timeline (increase(...[5m]))\n- Root Actors (stat)\n- Container Count ($cluster) (stat)\n- 按 $root_actor 重复分组: \n  - Pods of $root_actor (表: node/pod)\n  - Containers of $root_actor (表: node/pod/container)\n  - Container CPU (cores) [$root_actor] (timeseries)\n  - Container Memory (bytes) [$root_actor] (timeseries)\n\n说明\n- 查询统一使用隐藏 filter 变量，避免重复编写计算逻辑（用户可见变量仅负责候选/选择）。\n- 数据源: `GreptimeDB`\n- 刷新: 15s；采样步长: 15s\n- Exporter 为所有 actor 层级（root/namespace/pod/controller）周期性写入 `nokube_actor_status=1`，stop/lifecycle 事件写入 -1；Grafana 依靠 30s 窗口过滤可识别是否 alive\n- 容器筛选统一依赖 actor 心跳：pod actor 下的容器若 30s 内无心跳会自动从模板变量与面板中隐藏\n- 仅基于真实容器（已去除演示数据）；无新数据的容器不展示\n- 定义来源: `src/agent/general/grafana_manager.rs: import_actor_dashboard()`","x":6598,"y":2240,"width":622,"height":1220},
		{"id":"exporter-containers","type":"text","text":"## Exporter: 容器指标\n\n目标容器\n- 名称以 `nokube-pod-` 开头（`docker ps --format {{.Names}}` 过滤）\n- 仅来源于真实容器（docker ps + docker stats），不生成演示/模拟数据\n\n采集\n- `docker ps --format \"{{.Names}}\\t{{.Status}}\"` 获取容器名/状态\n- `docker stats --no-stream --format \"{{.CPUPerc}}\\t{{.MemUsage}}\\t{{.MemPerc}}\"` 获取 CPU 与内存\n\n心跳与 Freshness\n- 心跳: 每 15s 推送一次\n- Freshness: 面板用 `count_over_time(metric[30s]) > 0` 过滤，仅展示近 30s 活跃容器\n\n指标名与别名\n- `nokube_container_cpu_usage` → 别名 `nokube_container_cpu`（面板统一使用）\n- `nokube_container_mem_bytes`, `nokube_container_mem_percent`\n- Actor指标: `nokube_actor_info`, `nokube_actor_pod_status`, `nokube_actor_status`\n\n标签\n- 基本: `cluster_name`, `node`, `instance`, `container`, `container_name`\n- Pod/Actor 归属: `pod`, `pod_name`, `parent_deployment`/`parent_daemonset`, `root_actor`\n- 统一路径: `container_path=cluster/root_actor/pod/container`（与日志 `scope_name` 对齐）\n- 归一化: 由容器名推断 core，`upper_actor = <core>-<cluster>`\n","x":3650,"y":5525,"width":820,"height":500},
		{"id":"exporter-system","type":"text","text":"## Exporter: 系统指标\n\n采集\n- CPU 使用率: `/proc/stat`\n- CPU 逻辑核: `/proc/cpuinfo`（或 `/sys/devices/system/cpu/present` 兜底）\n- 内存占用: `/proc/meminfo` (MemTotal/MemAvailable)\n- 网络流量: `/proc/net/dev`（汇总非 `lo` 接口）\n\n指标名\n- `nokube_cpu_usage`, `nokube_cpu_cores`\n- `nokube_memory_usage`, `nokube_memory_used_bytes`, `nokube_memory_total_bytes`\n- `nokube_network_rx_bytes`, `nokube_network_tx_bytes`\n\n周期/新鲜度\n- Agent 内置 MetricsCollector: 推送间隔 15s（容器/Actor指标心跳）\n- Rust Exporter（exporter.rs）默认 30s（系统与容器聚合指标）；面板统一以 30s Freshness 过滤\n\n标签\n- `cluster_name`, `node`, `instance`（三者取自节点/集群上下文）","x":2780,"y":5325,"width":820,"height":560},
		{"id":"var-root-actor","type":"text","text":"## Variable: $root_actor\n- Query: query_result(last_over_time(nokube_actor_status{cluster_name=~\"$cluster\", actor_level=\"root\", canonical=\"1\"}[30s]) > 0)\n- 窗口: 30s actor 心跳\n- 数据依赖: nokube_actor_status (root)","x":6900,"y":3760,"width":700,"height":200},
		{"id":"var-container","type":"text","text":"## Variable: $container\n- Query: query_result(last_over_time(nokube_actor_status{cluster_name=~\"$cluster\", actor_level=\"pod\", root_actor=~\"$root_actor\", canonical=\"1\"}[30s]) > 0)\n- 窗口: 30s actor 心跳\n- 数据依赖: nokube_actor_status (pod)","x":6900,"y":3990,"width":720,"height":210},
		{"id":"var-node","type":"text","text":"## Variable: $node\n- Query: query_result(last_over_time(nokube_actor_status{cluster_name=~\"$cluster\", actor_level=\"pod\", root_actor=~\"$root_actor\", container=~\"$container\", canonical=\"1\"}[30s]) > 0)\n- 窗口: 30s actor 心跳\n- 数据依赖: nokube_actor_status (pod)","x":6900,"y":4220,"width":720,"height":210},
		{"id":"var-cluster","type":"text","text":"## Variable: $cluster\n- Query: label_values(nokube_container_cpu_cores, cluster_name)\n- 作用: 选择目标集群\n- 数据依赖: nokube_container_cpu_cores","x":6960,"y":4455,"width":640,"height":160},
		{"id":"grafana-shared-module","type":"text","text":"## Grafana Dashboard Shared Module\n- 位置: `src/agent/general/grafana_dashboards.rs`\n- 暴露 `actor_dashboard()` / `cluster_dashboard()`\n- MasterAgent 与 CommandModeAgent 共用\n- PromQL 统一维护 (regex 变量 + `> bool 0` 过滤)\n- 新面板从此扩展，保持导入流程一致","x":5000,"y":1970,"width":540,"height":400},
		{"id":"dash-links-panel","type":"text","text":"### 关键链接面板（Cluster 仪表盘内）\n使用 Text 面板 (markdown) 实现：\n- [Actor Dashboard](/d/nokube-actor-dashboard)\n- [Logs (MySQL)](/d/nokube-logs-mysql)\n- [HTTP 文件服务器](http://<head>:<http_port>)\n- [Greptime Metrics](http://<head>:<greptime_port>/v1/prometheus)","x":5810,"y":2085,"width":580,"height":280},
		{"id":"63020bf5856229b9","type":"text","text":"## Exporter 总览\n\n路径\n- `src/agent/general/exporter.rs`\n\n职责\n- 采集系统与容器指标，推送到 GreptimeDB (Influx 行协议)\n- 按配置轮询 etcd 获取 `ClusterConfig`\n- 仅基于真实容器（docker ps + docker stats），不生成演示/模拟数据\n\n推送目标\n- `{greptime}/v1/influxdb/write`（由 head 节点 IP + `monitoring.greptimedb.port` 组装）\n\n周期\n- metrics_interval 默认 30s\n- config_poll_interval 默认 10s\n- Agent MetricsCollector(容器/Actor) 心跳 15s；面板统一 30s Freshness 过滤（`count_over_time(metric[30s]) > 0`）\n\n指标与别名\n- CPU: `nokube_container_cpu_usage` → 别名 `nokube_container_cpu`（面板统一使用）\n- 内存: `nokube_container_mem_bytes`, `nokube_container_mem_percent`\n- Actor指标: `nokube_actor_info`, `nokube_actor_pod_status`, `nokube_actor_status`\n\n标签增强\n- 容器指标追加 `container_path=cluster/root_actor/pod/container`，与日志 `scope_name` 对齐，便于仪表盘联动\n\n支持\n- Cluster / Actor 仪表盘\n","x":2700,"y":4585,"width":530,"height":680},
		{"id":"dashboard-cluster","type":"text","text":"## Dashboard: Cluster\n\n面板布局\n- 关键链接 | cluster container mem | cluster cpu \n- cluser net rx                    |               cluster net tx \n- each node\n\t- node cpu                 |                   node mem  (both with detail node container usage)\n\n说明\n- 数据源: `GreptimeDB`\n- 时间范围: now-1h；刷新: 15s；采样步长: 15s\n- 心跳: exporter 每 15s 上报一次容器指标\n- Freshness 判定: 近 30s 内未收到新数据则视为下线；用 `count_over_time(metric[30s]) > 0` 过滤活跃容器\n- 主要维度: instance/node, container\n- 定义来源: `general::grafana_dashboards::cluster_dashboard()`","x":6461,"y":1720,"width":759,"height":460},
		{"id":"docker-ops-module","type":"text","text":"## 🐳 Docker 操作模块\n入口: `src/agent/general/docker_runner.rs`\n\n**命名链条**\n- `root_actor` (Actor name): etcd `/nokube/{cluster}/deployments|daemonsets/<actor>` 末段，串联容器、指标、日志\n- `pod`: Deployment → `<actor>`；DaemonSet → `<actor>-<node>`（节点维度）\n- `container`: Docker 名称 = `nokube-pod-<pod>`；`container_path = {cluster}/{root_actor}/{pod}/{container}`（日志 scope_name 与指标标签）\n- Workspace: `<workspace>/{configmaps|secrets}/<actor or resource>`\n\n**当前能力**\n- 单容器 workload：runtime 取 YAML `containers[0]` 构造 `DockerRunConfig`\n- 使用 `DockerRunner::{create,start,stop,remove_container}` 管理容器生命周期\n- 卷挂载 (ConfigMap/Secret/workspace bind) 与只读控制\n- 端口、网络参数等封装在 `DockerRunConfig`\n\n**GitOps 支持**\n- YAML 内嵌 ConfigMap 写入 workspace 后挂载 `/etc/config`\n- 拉取 etcd ConfigMap/Secret 并生成本地文件\n\n**安全基线**\n- 过滤空命令、清理环境变量输入\n- 仅统一模块落地 Docker 命令，避免临时 `docker run`\n\n**多容器支持计划（设计中）**\n1. runtime::deployment 遍历 YAML `containers`，生成 `nokube-pod-<pod>-<container>` 并写入 container_path\n2. DockerRunner 支持成组 create/stop/remove，保证更新/回收时容器集一致\n3. Exporter / 日志收集器按新 container_path 采集指标与 scope_name，面板变量继续联动\n4. Pod/Actor 等 etcd 元数据扩展为多容器结构，确保健康检查与回收覆盖每个容器","x":2970,"y":1600,"width":770,"height":452},
		{"id":"dash-cluster-home","type":"text","text":"## 监控面板规划\n- Cluster Dashboard 设置为默认首页\n- 顶部新增 ‘关键链接’ 面板，提供快捷跳转：\n  - Actor Dashboard (/d/nokube-actor-dashboard)\n  - Logs (MySQL) (/d/nokube-logs-mysql)\n  - HTTP 文件服务器 (Head 节点)\n  - Greptime Metrics (/v1/prometheus)","x":5810,"y":1720,"width":580,"height":300},
		{"id":"21029617ed1cf87d","type":"text","text":"","x":5780,"y":1700,"width":250,"height":4},
		{"id":"ea2e9375f8de9b78","type":"text","text":"## Metric: nokube_container_cpu\n容器 CPU 使用率（%），供 Cluster/Node CPU 面板堆叠。","x":8085,"y":5530,"width":700,"height":120},
		{"id":"6dd5a77cb7493db1","type":"text","text":"## Metric: nokube_node_mem_other_bytes\n节点非容器内存，Cluster/Node 内存面板堆叠项。","x":8090,"y":4560,"width":700,"height":100},
		{"id":"53bbafeffc8911e7","type":"text","text":"## Metric: nokube_actor_lifecycle\nActor 启停事件（start=1/stop=-1），当前 Grafana 预留待用。","x":8085,"y":4440,"width":710,"height":120},
		{"id":"9558151dadc662fc","type":"text","text":"## Metric: nokube_cpu_usage\n节点 CPU 利用率（%），用于 cluster dashboard 节点模板 (`label_values`).","x":8090,"y":4970,"width":700,"height":110},
		{"id":"53811a521b1b9eb4","type":"text","text":"## Metric: nokube_cpu_cores\n节点可用逻辑核数（目前 Grafana 未直接引用）。","x":8090,"y":5080,"width":700,"height":110},
		{"id":"eb63fca595bad3ee","type":"text","text":"## Metric: nokube_memory_usage\n节点内存利用率（%），当前 Grafana 未直接使用。","x":8090,"y":5190,"width":700,"height":110},
		{"id":"743be6174a9b2798","type":"text","text":"## Metric: nokube_network_rx_bytes\n节点网络下行累计字节，Network RX 面板 rate() 源。","x":8090,"y":5300,"width":700,"height":115},
		{"id":"a2ec4b6c3481a869","type":"text","text":"## Metric: nokube_network_tx_bytes\n节点网络上行累计字节，Network TX 面板 rate() 源。","x":8090,"y":5415,"width":700,"height":115},
		{"id":"aae4556fb8648bc3","type":"text","text":"## Metric: nokube_container_mem_bytes\n容器内存字节数，表格/计数/时序的核心来源。","x":8090,"y":4310,"width":715,"height":100},
		{"id":"grafana-import-flow","type":"text","text":"## Grafana Dashboard Import Flow\n- ServiceModeAgent(head) 启动 Grafana → 探活通过 → 调用 GrafanaManager 导入 cluster/actor 默认面板，设置首页\n- CLI `new-or-update` 保持可用：CommandModeAgent 同样复用 GrafanaManager\n- 控制侧 (MasterAgent) 仍可按需触发导入，三条路径共享同一套 JSON 模板\n- 数据目录挂载 `{workspace}/data/grafana`，仪表盘导入只需在首次/目录被清空时执行","x":4760,"y":980,"width":660,"height":420},
		{"id":"docker-config-example","type":"text","text":"## ConfigMap 挂载示例\n\n**GitOps YAML结构:**\n```yaml\nspec:\n  configMap:\n    data:\n      requirements.txt: \"flask==2.3.2\\nrequests==2.31.0\"\n      webhook-server.py: \"#!/usr/bin/env python3\\n...\"\n  webhookDeployment:\n    containerSpec:\n      image: python:3.10-slim\n      command: [\"/bin/bash\"]\n      args: [\n        \"-c\", \n        \"pip install -r /etc/config/requirements.txt && python /etc/config/webhook-server.py\"\n      ]\n```\n\n**生成的Docker命令:**\n```bash\ndocker run -d \\\n  --name nokube-pod-{deployment-name} \\\n  -v {workspace}:/pod-workspace \\\n  -v {workspace}/configmaps/{deployment-name}:/etc/config:ro \\\n  -e FLASK_PORT=8080 \\\n  python:3.10-slim \\\n  /bin/bash -c \"pip install -r /etc/config/requirements.txt && python /etc/config/webhook-server.py\"\n```\n\n**文件系统结构:**\n```\n{workspace}/\n├── configmaps/\n│   └── {deployment-name}/\n│       ├── requirements.txt\n│       └── webhook-server.py\n└── ...\n```\n\n**动态变量说明:**\n- `{workspace}` - 工作空间路径 (默认: /opt/devcon/pa/nokube-workspace)\n- `{deployment-name}` - 部署名称 (如: gitops-webhook-server-home-cluster)\n- `{cluster-name}` - 集群名称","x":1723,"y":2482,"width":700,"height":700},
		{"id":"n-fix-workspace","type":"text","text":"## ConfigMap 挂载实现（细化）\n- 工作目录来源：从 ClusterConfig 读取当前节点 workspace（避免硬编码）。\n- 写入：将 ConfigMap data 写入 `{workspace}/configmaps/{deployment}` 目录，若不存在先创建。\n- 挂载：通过 DockerRunConfig.add_volume 将上述目录以只读方式挂载到容器 `/etc/config`。\n- 生效面：Deployment/DaemonSet 统一使用节点 workspace，KubeController 初始化亦保持一致。\n- 相关文件：src/agent/service_agent/service_mode_agent.rs（统一容器创建逻辑）","x":1723,"y":3322,"width":700,"height":360},
		{"id":"9cf4ae7f0bc843ff","type":"text","text":"## Metric: nokube_container_cpu_cores\n容器折算 CPU 核数，用于 Root Actors 与 CPU 时序。","x":8080,"y":4190,"width":705,"height":100},
		{"id":"9637b6dd8a712c9e","type":"text","text":"## Metric: nokube_actor_status (pod)\nActor 存活心跳（1/-1），Grafana 模板变量依赖 `actor_level=pod` 统计活跃 root_actor/容器。\n- 关联变量: $root_actor / $container / $node\n- 过滤窗口: last_over_time(nokube_actor_status{actor_level=\"pod\"}[30s]) > 0","x":7920,"y":4020,"width":910,"height":180},
		{"id":"02e699f71e2275ad","type":"text","text":"## Metric: nokube_memory_used_bytes\n节点已用内存字节（当前 Grafana 未直接引用）。","x":8090,"y":4770,"width":710,"height":100},
		{"id":"4e81f771478c5049","type":"text","text":"## Metric: nokube_memory_total_bytes\n节点总内存字节（当前 Grafana 未直接引用）。","x":8090,"y":4870,"width":710,"height":100},
		{"id":"be26e494f4ce5f63","type":"text","text":"## Metric: nokube_node_mem_free_bytes\n节点剩余内存，Cluster/Node 内存面板堆叠项。","x":8090,"y":4660,"width":700,"height":100},
		{"id":"grafana-manager-general","type":"text","text":"## GrafanaManager\n- 模块位置: `src/agent/general/grafana_manager.rs`\n- 提供 Grafana 仪表盘导入接口：`import_cluster_dashboard()` / `import_actor_dashboard()` / `import_logs_dashboard()`\n- ServiceModeAgent(head 节点) 在 Grafana `/api/health` 就绪后调用，确保默认面板自动落地\n- 依赖共享模板(`general::grafana_dashboards`)与 Grafana HTTP API","x":2920,"y":520,"width":580,"height":420},
		{"id":"2faefa3b8c902c4d","type":"text","text":"## Panel: Cluster Container Memory (stacked)\n- Grafana Graph\n- 指标: sum last_over_time(nokube_container_mem_bytes) + node_mem_other/free\n- 变量: $cluster\n- 场景: 集群级容器内存趋势","x":9125,"y":4840,"width":800,"height":180},
		{"id":"d8835376af30e59a","type":"text","text":"## Panel: Network TX (Upload)\n- Grafana Graph\n- 指标: rate(nokube_network_tx_bytes[5m])\n- 变量: $cluster, $node","x":9205,"y":5200,"width":840,"height":170},
		{"id":"1cab9152c78575fa","type":"text","text":"## Panel: Cluster Container CPU (stacked %)\n- Grafana Graph\n- 指标: sum by (container)(nokube_container_cpu)\n- 变量: $cluster","x":9205,"y":5370,"width":840,"height":160},
		{"id":"8ecf221a16634edd","type":"text","text":"## Panel: Node CPU by Container [$node]\n- Grafana Graph (repeat)\n- 指标: nokube_container_cpu{node=~\"$node\"}\n- 变量: $cluster, $node","x":9205,"y":5530,"width":840,"height":160},
		{"id":"c0d92205384ae5ff","type":"text","text":"## Panel: Container Count\n- Grafana Stat\n- 数据: count(count by (pod,container)(nokube_container_mem_bytes))\n- 变量: $cluster, $root_actor, $container\n- 过滤: 与 last_over_time(nokube_actor_status{actor_level=\"pod\"}[30s]) > 0 绑定\n- 作用: 统计符合筛选条件的容器数","x":9173,"y":3320,"width":680,"height":200},
		{"id":"bb8189dc5a9eeffb","type":"text","text":"## Panel: Root Actors\n- Grafana Stat\n- 数据: count(count by (root_actor)(nokube_container_cpu_cores))\n- 变量: $cluster\n- 作用: 展示活跃 root_actor 数量","x":9173,"y":3460,"width":680,"height":160},
		{"id":"d33f4f3976ad1ed5","type":"text","text":"## Panel: Pods Table\n- Grafana Table\n- 数据: sum by (pod,node)(nokube_container_mem_bytes)\n- 变量: $cluster, $root_actor, $container\n- 过滤: last_over_time(nokube_actor_status{actor_level=\"pod\"}[30s]) > 0\n- 展示: 节点/Pod 的内存占用","x":9173,"y":3600,"width":680,"height":210},
		{"id":"05a61dd0441d01bf","type":"text","text":"## Panel: Containers Table\n- Grafana Table\n- 数据: nokube_container_mem_bytes (含 container_path 链接)\n- 变量: $cluster, $root_actor, $container\n- 过滤: last_over_time(nokube_actor_status{actor_level=\"pod\"}[30s]) > 0\n- 展示: 节点/Pod/Container 明细","x":9173,"y":3760,"width":680,"height":220},
		{"id":"5335dde14d1038ab","type":"text","text":"## Labels: container_path 等\n`cluster/root_actor/pod/container` 组合标签，供容器明细与日志联动。","x":9153,"y":2920,"width":705,"height":100},
		{"id":"63a7919ba26e1c77","type":"text","text":"the_proxy\n特殊actor协程，一个agent一个，用于聚合所有 k8s actor 一段时间内的请求（一般就是校验其从属以及管控的actor是否alive）\n当前使用: ServiceModeAgent -> KubeController -> actors 已接入, etcd /nokube/{cluster}/actors/*/alive 持续刷新","x":583,"y":2347,"width":360,"height":201},
		{"id":"the-proxy-keepalive-task","type":"text","text":"## the_proxy Keepalive [独立task]\n归属: the_proxy\n触发: tokio::spawn (periodic_keepalive)\n周期: keepalive_interval (默认 5s)\n职责: 续租 alive key, 超时标记 Dead\n关键代码: src/k8s/the_proxy.rs::periodic_keepalive\n当前使用: ServiceModeAgent::run 启动时自动 spawn (src/agent/service_agent/service_mode_agent.rs)","x":1103,"y":2332,"width":520,"height":300},
		{"id":"the-proxy-alive-task","type":"text","text":"## the_proxy Alive 消费 [独立task]\n归属: the_proxy\n触发: tokio::spawn (handle_alive_requests)\n模式: 异步通道循环\n职责: 接收 ActorAliveRequest, 写 `/nokube/{cluster}/actors/{path}/alive` 带租约条目\n关键代码: src/k8s/the_proxy.rs::handle_alive_requests\n当前使用: DaemonSet/Deployment/Pod actors 通过 proxy_tx 实时上报 (src/k8s/actors.rs)","x":1103,"y":2660,"width":520,"height":320},
		{"id":"actor-fullpath","type":"text","text":"## Actor Fullpath 标识\n\n定义\n- Canonical: `cluster/root_actor/pod/container`。\n- Exporter 推送 `container_path` 标签 (canonical=1)；日志 `scope_name` 同步此路径。\n\n用途\n- Actor 层级钻取、仪表盘联动、容器去重。\n- Grafana 变量 `fullpath` 与 legacy `container_path` 兼容，可用于跨面板跳转、日志筛选。\n\n备注\n- CLI/Agent 统一依赖该标识，后续 Actor 管理功能复用。","x":892,"y":4292,"width":720,"height":375},
		{"id":"root-actor-definition","type":"text","text":"## Root Actor 概念\n- 定义: Actor 层级的根节点，用于聚合 Pod/容器指标与日志\n- 分类: deployment/<name> 或 daemonset/<name>\n- 生成: 创建 Deployment/DaemonSet Actor 时自动生成顶层路径\n- 作用: root_actor 标签指导 Grafana 仪表盘与日志聚合","x":962,"y":3892,"width":600,"height":260},
		{"id":"a1985af03c62db31","type":"text","text":"## Panel: Container Memory 时序\n- Grafana Timeseries\n- 数据: sum by (pod,container,node)(nokube_container_mem_bytes)\n- 叠加: last_over_time(nokube_node_mem_other_bytes/free_bytes)\n- 变量: $cluster, $root_actor, $container, $node\n- 过滤: last_over_time(nokube_actor_status{actor_level=\"pod\"}[30s]) > 0","x":9173,"y":4290,"width":800,"height":240},
		{"id":"18146762550f3fd1","type":"text","text":"## Panel: Node Memory by Container [$node]\n- Grafana Graph (repeat)\n- 指标: last_over_time(nokube_container_mem_bytes{node}[60s]) + node_mem_other/free\n- 变量: $cluster, $root_actor, $container, $node\n- 过滤: last_over_time(nokube_actor_status{actor_level=\"pod\"}[30s]) > 0","x":9173,"y":3920,"width":680,"height":220},
		{"id":"cc3c1a31ff6a6d92","type":"text","text":"## Panel: Network RX (Download)\n- Grafana Graph\n- 指标: rate(nokube_network_rx_bytes[5m])\n- 变量: $cluster, $node","x":9205,"y":5035,"width":800,"height":160},
		{"id":"2b2c75cfe9dfdc26","type":"text","text":"## Panel: Container CPU 时序\n- Grafana Timeseries\n- 数据: sum by (pod,container,node)(nokube_container_cpu_cores)\n- 变量: $cluster, $root_actor, $container\n- 过滤: 与 last_over_time(nokube_actor_status{actor_level=\"pod\"}[30s]) > 0 联动\n- 作用: 观察容器 CPU cores 随时间变化","x":9173,"y":4070,"width":680,"height":220},
		{"id":"cli-service-status-bridge","type":"text","text":"### new-or-update ↔ Service Agent\n- CLI 仅在当次部署生成 deployment_version（时间戳 + UUID），随 extra_params(base64 JSON) 传给远端 agent\n- command/service agent 读取版本号后回写模块状态，不污染共享配置\n- CLI 轮询 `/service_agents/.../deployments/{version}`，汇总所有节点结果","x":680,"y":800,"width":760,"height":260},
		{"id":"n-gitops-note","type":"text","text":"## GitOps Controller 部署要点\n- 镜像：python:3.10-slim；容器名：nokube-pod-<deployment>。\n- ConfigMap：gitops-scripts-<cluster> 挂载至 /etc/config（requirements.txt, gitops-controller.py）。\n- 命令：pip install -r /etc/config/requirements.txt && python /etc/config/gitops-controller.py。\n- 真实状态以 etcd /pods 与容器为准。","x":1088,"y":1934,"width":520,"height":320},
		{"id":"kubecontroller-overview","type":"text","text":"## KubeController（中心回收）\n\n- 归属路径: `service/{node}/kubecontroller`（由 ServiceModeAgent 启动）\n- 共享 TheProxy 发送端，负责 actor 心跳续约、孤儿回收\n- 每 15s 调度巡检：遍历 deployments/daemonsets，触发 pod.cleanup_if_orphaned()\n- Actor 扫描: 轮询 `/nokube/{cluster}/deployments|daemonsets/`，直接构建/重建容器\n- 接口：\n  - `register_container_listener(tx)`：统一容器事件总线（create/stop），LogCollector、Exporter 等订阅后必须先执行一次全量对账\n- 与 Grafana Freshness 对齐：确保 30s 内无心跳的容器全部被清空","x":852,"y":3052,"width":820,"height":360},
		{"id":"actor-lifecycle","type":"text","text":"## Actor 协程生命周期与治理\n\n### 角色与路径\n- ServiceAgent: `service/{node}/agent`\n- KubeController: `service/{node}/kubecontroller`\n- DeploymentActor: `service/{node}/deployment/{name}`\n- DaemonSetActor: `service/{node}/daemonset/{name}`\n\n> 统一 ActorPath 便于跨节点协同\n\n### 存活与父子关系\n- 存活键: `/nokube/{cluster}/actors/{actor_path}/alive` (etcd 带租约)\n  - `lease_ttl=15s`, keepalive `5s`\n  - 值包含: `last_alive`, `node`, `version`\n- 父键: `/nokube/{cluster}/actors/{actor_path}/parent` → 父ActorPath\n- 子集合: `/nokube/{cluster}/actors/{actor_path}/children` → 子ActorPath列表\n\n### 孤儿回收（中心调度）\n- KubeController 每 15s 扫描 deployments/daemonsets，逐个指派 pod.cleanup_if_orphaned()\n- cleanup_if_orphaned() 由控制面触发：校验父级 etcd 键与 alive 租约，必要时停止容器并清理 `/pods`、`/events`\n- Actor 不再自启伴随协程，自身仅负责业务逻辑与心跳上报\n\n### 心跳判定与可观测性\n- Deployment/DaemonSet/Pod Actor 统一写入 `lease_ttl=15s` 的 alive 心跳；TheProxy 5s keepalive 确保租约续约\n- `PodDescription` 读取 alive 信息，若 `last_alive` 超过 `2 * lease_ttl` (默认 30s) 判定为 Dead，CLI/Grafana 会隐藏这些容器\n- Freshness 规则与 Dashboard 的 `count_over_time(metric[30s]) > 0` 对齐\n\n### 信号通道\n- `/nokube/{cluster}/actors/{actor_path}/signal`: `shutdown|drain|restart`\n- 由父或控制面写入；子消费后写 `/ack`\n\n### 统一 Actor 接口\n- 控制面统一调用 `Actor::check()` 获取治理计划；返回值统一为需要关闭/重建的资源列表与要下发的信号\n- 子 Actor 的 `check()` 递归下沉至 pod.check，对齐父子 ActorPath，封装容器、事件等实际处置动作\n- KubeController 汇总 `check()` 结果后统一执行，保持接口一致性并支持后续扩展更多 Actor 类型\n\n### 本地容器命名\n- 统一为 `nokube-pod-{deploymentName}`，便于跨模块回收\n","x":-8,"y":3052,"width":770,"height":1240},
		{"id":"d8d98b5f9f5121be","type":"text","text":"k8s actor \n对应etcd 某个配置\n此外这个actor的alive应该冗余一个key，并且按照这个actor的粒度设置lease\n定期向 the proxy发出请求，保活自己的lease以及检查自己关联组件","x":98,"y":1800,"width":300,"height":195},
		{"id":"k8s-abstraction","type":"text","text":"## Actor 模拟层\nk8s中的daemonset、deployment、pod 统一称作actor，为某个agent里的一个协程所管控\n\n**src/k8s/**\n- objects.rs\n- controllers.rs\n- storage.rs\n- heartbeat.rs\n\n📦 Pod 管理\n⚖️ DaemonSet/Deployment\n🔐 Config/Secret 存储\n💓 生命周期监控","x":213,"y":2052,"width":370,"height":430},
		{"id":"kubecontroller-actor-scan-task","type":"text","text":"## KubeController Actor 扫描 [独立task]\n归属: KubeController (start_actor_monitor)\n周期: 15s\n职责: 轮询 `/nokube/{cluster}/deployments|daemonsets/`，对比 runtime::deployment::calc_hash_u64 生成的 YAML checksum\n  - 新增/变更: 新 key 或 checksum 变化 → 调用 runtime::deployment::create_deployment_container 重建容器\n  - 心跳缺失/孤儿: Actor alive key 缺失/过期 → 调用 pod.cleanup_if_orphaned() 清理容器与 etcd\n  - 递归校验: KubeController 仅管控 DaemonSet/Deployment Actor，先调用它们统一的 `check()` 接口，再由 Actor 递归下沉至 pod.check 收敛待关闭资源（当前主要是 Docker 容器）\n  - 最终执行: `check()` 返回的关闭计划统一回传给 KubeController，在控制层集中执行，保证 Actor 接口一致性与递归扩展能力\n关键代码: src/k8s/controllers.rs::start_actor_monitor","x":1022,"y":3502,"width":650,"height":260},
		{"id":"service-agent-summary","type":"text","text":"## ServiceModeAgent (容器/调度中枢)\n\n职责\n- 管理 TheProxy、KubeController、Exporter 等子组件生命周期\n- 启动 / 监护本地系统服务 (Grafana、GreptimeDB、HTTP Server)\n- Grafana 容器挂载 `{workspace}/config/*` + `{workspace}/data/grafana`，避免重复迁移，并在探活后触发仪表盘导入\n- 初始化阶段写入 `/nokube/{cluster}/pods|events` 状态 (绑定服务)\n\n网络约束\n- Grafana/Greptime/HTTP 均绑定 head 节点 IP（ClusterConfig.nodes[role=head].ssh_url），外部 API 调用必须指向该 IP","x":-100,"y":535,"width":540,"height":460},
		{"id":"service-agent-status-sync","type":"text","text":"## Service Agent Startup\n- new-or-update 生成 `deployment_version`，command/service agent 共享\n- `/nokube/{cluster}/service_agents/{node}/deployments/{version}` 按模块记录状态\n- compare-and-swap 写入：成功 → Success，失败 → Failed + message\n- Agent 定期打印模块 summary，CLI 监控所有节点，任一 Failed 立即终止","x":-120,"y":1120,"width":900,"height":260},
		{"id":"cli-apply","type":"text","text":"## CLI: apply\n\n用法\n- `nokube apply -f <file> [--cluster <name>] [--dry-run]`\n- `cat manifest.yaml | nokube apply --cluster <name>`\n\n说明\n- 支持多文档 YAML；未指定 `-f` 时从 stdin 读取\n- `--dry-run` 仅解析/打印，不写入 etcd\n\n示例\n- `nokube apply -f gitops.yaml --cluster home-cluster`","x":2280,"y":-577,"width":360,"height":362},
		{"id":"cli-get","type":"text","text":"## CLI: get\n\n用法\n- `nokube get <pods|deployments|daemonsets|configmaps|secrets> [name] [-o table|json|yaml] [-c <name>] [--all-namespaces]`\n\n说明\n- 默认输出 `-o table`；`-c` 等同 `--cluster`\n- services 列表暂未实现\n\n示例\n- `nokube get pods -c home-cluster -o table`","x":2280,"y":-174,"width":360,"height":362},
		{"id":"n-hostport","type":"text","text":"## Decision: hostPort vs Service\n- 配置 hostPort 后，Pod 在节点 NodeIP:hostPort 直接可达，不依赖 Service。\n- 仍建议：为稳定发现/DNS 与负载均衡叠加 ClusterIP Service。\n- 跨节点对外访问：用 NodePort/LoadBalancer（需要 Service）。\n- 代价：同节点端口冲突、调度受限。","x":2810,"y":-620,"width":520,"height":300},
		{"id":"n-ports","type":"text","text":"## Ports/hostPort 支持（TODO）\n- 解析 spec.template.spec.containers[].ports/hostPort → DockerRunConfig.add_port()。\n- 如需 Service 能力：实现 apply_service 持久化 + get/describe service。\n- 策略：hostPort 用于本机暴露；Service 提供发现与负载。","x":2835,"y":-293,"width":520,"height":300},
		{"id":"cli-describe","type":"text","text":"## CLI: describe\n\n用法\n- `nokube describe <pod|deployment|daemonset|configmap|secret|service> <name> [-c <name>]`\n\n说明\n- 从 etcd 或内置渲染输出资源详情\n\n示例\n- `nokube describe pod gitops-controller-0 -c home-cluster`","x":1900,"y":-577,"width":360,"height":362},
		{"id":"cli-agent-service","type":"text","text":"## CLI: agent-service\n\n用法\n- `nokube agent-service [--extra-params <BASE64(JSON)>]`\n\n说明\n- 常驻服务模式运行 Agent","x":1450,"y":-168,"width":360,"height":362},
		{"id":"cli-agent-command","type":"text","text":"## CLI: agent-command\n\n用法\n- `nokube agent-command --extra-params <BASE64(JSON)>`\n\n说明\n- 一次性命令模式；`extra-params` 必须包含 `cluster_name`\n\n示例\n- `echo -n '{\"cluster_name\":\"home-cluster\"}' | base64`","x":1450,"y":-571,"width":360,"height":362},
		{"id":"9213010bd51b4eba","type":"text","text":"docker启动，稳定隔离运行","x":-100,"y":430,"width":160,"height":90},
		{"id":"cli-logs","type":"text","text":"## CLI: logs\n\n用法\n- `nokube logs <pod> [-c <name>] [--follow] [--tail N]`\n\n说明\n- 结合 etcd 状态/事件；Running 时展示示例日志；支持 `--follow`\n\n示例\n- `nokube logs my-pod -c home-cluster --tail 100`","x":1900,"y":-174,"width":360,"height":362},
		{"id":"cli-new-or-update","type":"text","text":"## CLI: new-or-update\n\n用法\n- `nokube new-or-update [config.yaml]`\n\n说明\n- 未提供文件时生成模板 `cluster-config-template.yaml` 并提示二次执行\n- 持久化集群配置到 etcd 并触发部署/更新\n\n示例\n- `nokube new-or-update ./home-cluster.yaml`","x":520,"y":-545,"width":360,"height":362},
		{"id":"cli-monitor","type":"text","text":"## CLI: monitor\n\n用法\n- `nokube monitor --cluster <name>`\n\n说明\n- 启动 GreptimeDB + Grafana，自动配置数据源与仪表盘\n\n示例\n- `nokube monitor --cluster home-cluster`","x":520,"y":-142,"width":360,"height":362},
		{"id":"remote-control","type":"text","text":"## Remote Control\n\n**src/remote_ctl/**\n- ssh_manager.rs\n- deployment_controller.rs\n\n🔗 SSH 连接管理\n🚀 分布式部署\n\n### 🐳 Docker镜像构建与分发\n**prepare_dependencies()新增功能:**\n1. 构建包含Docker的nokube镜像\n   ```dockerfile\n   FROM ubuntu:22.04\n   RUN apt-get install docker.io python3-pip\n   COPY target/nokube /usr/local/bin/nokube\n   ```\n2. 导出镜像为tar包: `docker save -o nokube-image.tar`\n3. SSH上传tar包到各节点\n4. 远程加载镜像: `docker load -i nokube-image.tar`\n\n**优势:**\n✅ 避免每次容器启动重新下载\n✅ 镜像一次构建，多节点复用\n✅ 离线环境支持\n✅ 网络带宽节省\n\n### 📂 文件上传接口保障\n- 自动创建远程父目录: `mkdir -p <parent>`\n- 自动设置目录归属为当前SSH用户: `chown -R {user}:{user} <dir>`\n- 单文件上传: `upload_file` / `force_upload_file`\n- 目录上传: `upload_directory` (递归处理并统一权限)\n- 调用方无需额外 mkdir/chown，接口已内建","x":-29,"y":-630,"width":510,"height":860},
		{"id":"n-distribution-flow","type":"text","text":"## 分发流程 (基于 HTTP)\n1) 本地构建 & 打包\n2) 上传到 Head HTTP 目录\n3) 启动 http.server 容器 (python:3.10-slim)\n4) 节点下载: `http://<head>:<port>/releases/nokube/...`\n   - cmdagent 通过 curl 下载 `bin/`+`lib/` 后执行\n   - service agent 在容器内使用相同来源获取依赖\n5) 不再预分发到各节点 (无 SSH 逐点拷贝)\n","x":920,"y":-540,"width":440,"height":315},
		{"id":"gitops-extension","type":"text","text":"## GitOps 扩展\n\n**examples/gitops/**\n- 自动化部署\n- 配置同步\n\n🔧 **ConfigMap 挂载支持**\n- YAML内嵌配置文件\n- 自动文件系统映射\n- /etc/config 标准挂载","x":700,"y":-960,"width":230,"height":190},
		{"id":"architecture-principles","type":"text","text":"## 架构原则\n\n### 🔧 最小变更原则\n- 文件分布即模块规划\n- 严格错误处理\n- 无默认值策略\n\n### 🏗️ 容器化运行\n- Service Agent 使用 --pid\n- 观测宿主机信息\n- 统一进程内逻辑\n\n### 📊 监控绑定\n- 集群部署监控\n- 节点 IP 连接\n- 禁用 localhost","x":1070,"y":-920,"width":250,"height":200},
		{"id":"agent-system","type":"text","text":"## Agent 系统\n\n**src/agent/**\n- general/ 通用功能\n- master_agent/ 主代理\n- service_agent/ 服务代理\n\n🤖 远程命令执行\n📈 监控数据收集\n🐳 容器管理","x":-400,"y":-50,"width":300,"height":300},
		{"id":"nokube-core","type":"text","text":"# Nokube-rs Core\n\n分布式服务管理器\n- 集群初始化\n- 部署控制\n- 配置管理","x":-400,"y":-275,"width":200,"height":100},
		{"id":"config-module","type":"text","text":"## Config 模块\n\n**src/config/**\n- etcd_manager.rs\n- config_manager.rs\n\n🔧 集群配置存储\n📊 节点配置管理","x":-755,"y":-175,"width":260,"height":275},
		{"id":"n-nokube-artifacts","type":"text","text":"## Nokube 打包 (HTTP 分发)\n- 产物目录 (Head 节点): `<workspace>/<mount_subpath>/releases/nokube`\n  - `bin/nokube`\n  - `lib/libcrypto.so.1.1`, `lib/libssl.so.1.1` (可选)\n  - `nokube-image.tar` (可选: 预构建镜像)\n  - `manifest.json`, `install.sh`\n- 生成时机: CLI `new-or-update` 阶段\n- 说明: GitOps Canvas 中 HTTP Server 节点亦有标注","x":-720,"y":-750,"width":520,"height":360},
		{"id":"cluster-config","type":"text","text":"## 集群配置文件\n\n**cluster-config.yaml**\n\n```yaml\ncluster_name: home-cluster\n\nnodes:\n  - ssh_url: \"10.126.126.234:2222\"\n    name: \"pinghu-container\"\n    role: \"head\"\n    workspace: \"/opt/devcon/pa/nokube-workspace\"\n    storage:\n      type: \"local\"\n      path: \"/data/ray/head\"\n    users:\n      - userid: \"pa\"\n        password: \"74123\"\n```\n\n🔧 **Workspace配置来源:**\n1. **集群配置文件** - 每个节点的workspace字段\n2. **代码硬编码** - ServiceAgent中的默认路径\n3. **动态传递** - 通过ClusterConfig传递给Docker操作模块\n\n📂 **实际路径构建:**\n- 基础路径: `{node.workspace}`\n- ConfigMap路径: `{workspace}/configmaps/{deployment-name}`\n- 存储路径: `{workspace}/{storage.path}`","x":-1200,"y":1130,"width":720,"height":740},
		{"id":"etcd-storage","type":"text","text":"## etcd 分布式存储\n\n### 数据结构:\n**业务数据:**\n- `/nokube/{cluster}/pods/{name}` - Pod状态\n- `/nokube/{cluster}/events/pod/{name}` - Pod事件\n- `/nokube/{cluster}/deployments/{name}` - Deployment配置\n- `/nokube/{cluster}/daemonsets/{name}` - DaemonSet配置\n- `/nokube/{cluster}/configmaps/{name}` - ConfigMap\n- `/nokube/{cluster}/secrets/{name}` - Secret\n- `cluster/{name}` - 集群元数据\n- `k8s/configmap/{ns}/{name}` - Actor ConfigMap\n- `k8s/secret/{ns}/{name}` - Actor Secret\n\n**Actor存活监控:**\n- `/nokube/{cluster}/actors/{actor-path}/alive` - Actor存活状态\n  - 包含lease_ttl、last_alive时间戳\n  - the_proxy定期更新\n  - 超时标记为Dead\n\n### 写入者:\n- ConfigManager (集群配置)\n- ServiceAgent (Pod状态/事件)\n- ActorStorage (Actor资源)\n- **TheProxy (Actor存活状态)**\n\n### 读取者:\n- ServiceAgent (部署配置)\n- Exporter (集群配置)\n- CLI (Pod状态查询)\n- **TheProxy (Actor存活监控)**","x":-1260,"y":280,"width":680,"height":760},
		{"id":"nokube-config","type":"text","text":"## Nokube 全局配置\n\n路径\n- 用户级: `~/.nokube/config.yaml` (优先)\n- 全局级: `/etc/.nokube/config.yaml`\n- Agent 容器读取: `/etc/.nokube/config.yaml`（部署时将 `{workspace}/config/config.yaml` 挂载）\n\n格式 (YAML)\n```yaml\netcd_endpoints:\n  - 'http://10.0.0.10:2379'\n  - 'http://10.0.0.11:2379'\n```\n⚠️ 端点必须包含 `http://` 或 `https://` 前缀\n\n读取优先级\n1. 用户级 `~/.nokube/config.yaml`\n2. 全局级 `/etc/.nokube/config.yaml`\n\n配置方法\n- 本机创建上述文件并填入 `etcd_endpoints`\n- 部署时，控制器上传到每节点 `{workspace}/config/config.yaml`\n- 启动 Agent 时绑定为容器内 `/etc/.nokube/config.yaml`\n\n部署分布\n- 本地 CLI/控制器: 读取本机配置\n- 远程节点: `{workspace}/config/config.yaml` → 容器 `/etc/.nokube/config.yaml`（供 Agent/TheProxy 访问 etcd）\n- 相关 etcd 存储键：\n  - ClusterMeta: `cluster/{name}`\n  - ClusterConfig: `{cluster_name}`\n  - Actor: `/nokube/{cluster}/(configmaps|secrets|deployments|daemonsets|pods|events/pod)`","x":-1400,"y":-880,"width":560,"height":980},
		{"id":"service-agent-module-grafana","type":"text","text":"### Startup → Module • Grafana\n- 准备 `{workspace}/config/*` 与 `{workspace}/data/grafana`\n- docker run `greptime/grafana-greptimedb` 挂载 ini/datasource/dashboard/data\n- 探活 `/api/health` (600s/2s) → 设置首页、GrafanaManager 导入 cluster/actor 面板","x":1040,"y":1420,"width":600,"height":200},
		{"id":"service-agent-module-greptime","type":"text","text":"### Startup → Module • GreptimeDB\n- 准备 `{workspace}/data/greptimedb` 等持久化目录并挂载\n- docker run `greptime/greptimedb` 暴露 HTTP/MySQL，提供 `/v1/prometheus` 与 `/v1/influxdb/write`\n- Exporter / LogCollector 使用 `nokube-greptimedb` 作为指标与日志通道","x":1040,"y":1200,"width":620,"height":200}
	],
	"edges":[
		{"id":"edge-1","fromNode":"nokube-core","fromSide":"left","toNode":"config-module","toSide":"right","label":"配置读取"},
		{"id":"edge-2","fromNode":"nokube-core","fromSide":"bottom","toNode":"agent-system","toSide":"top","label":"代理管理"},
		{"id":"edge-3","fromNode":"nokube-core","fromSide":"right","toNode":"remote-control","toSide":"left","label":"远程部署"},
		{"id":"edge-5","fromNode":"agent-system","fromSide":"bottom","toNode":"30cdd7fa9b891781","toSide":"left"},
		{"id":"edge-service-etcd","fromNode":"k8s-abstraction","fromSide":"left","toNode":"etcd-storage","toSide":"right","label":"读取配置，部署actor"},
		{"id":"edge-cli-etcd","fromNode":"nokube-core","fromSide":"left","toNode":"etcd-storage","toSide":"right","label":"查询Pod状态"},
		{"id":"edge-docker-k8s","fromNode":"k8s-abstraction","fromSide":"right","toNode":"docker-ops-module","toSide":"left","label":"Pod容器化"},
		{"id":"edge-docker-example","fromNode":"docker-ops-module","fromSide":"left","toNode":"docker-config-example","toSide":"top","label":"实现示例"},
		{"id":"edge-config-workspace","fromNode":"cluster-config","fromSide":"right","toNode":"docker-config-example","toSide":"top","color":"4","label":"{workspace}配置来源"},
		{"id":"edge-config-etcd","fromNode":"cluster-config","fromSide":"top","toNode":"etcd-storage","toSide":"bottom","label":"集群配置存储"},
		{"id":"edge-config-docker","fromNode":"cluster-config","fromSide":"right","toNode":"docker-ops-module","toSide":"left","label":"workspace路径"},
		{"id":"edge-var-cluster","fromNode":"9cf4ae7f0bc843ff","fromSide":"left","toNode":"var-cluster","toSide":"right","label":"变量来源"},
		{"id":"edge-var-root","fromNode":"9637b6dd8a712c9e","fromSide":"left","toNode":"var-root-actor","toSide":"right","label":"变量来源"},
		{"id":"edge-var-container","fromNode":"9637b6dd8a712c9e","fromSide":"left","toNode":"var-container","toSide":"right","label":"变量来源"},
		{"id":"edge-var-node","fromNode":"9637b6dd8a712c9e","fromSide":"left","toNode":"var-node","toSide":"right","label":"变量来源"},
		{"id":"03a2ca3d55d61bc6","fromNode":"remote-control","fromSide":"bottom","toNode":"9213010bd51b4eba","toSide":"top"},
		{"id":"151253ad588032ae","fromNode":"config-module","fromSide":"bottom","toNode":"029a051cde4f5915","toSide":"top"},
		{"id":"c7f595250ae29636","fromNode":"nokube-config","fromSide":"right","toNode":"config-module","toSide":"left"},
		{"id":"edge-gitops-note","fromNode":"k8s-abstraction","fromSide":"right","toNode":"actor-lifecycle","toSide":"top"},
		{"id":"edge-fix-configmap","fromNode":"docker-config-example","fromSide":"bottom","toNode":"n-fix-workspace","toSide":"top","label":"ConfigMap 挂载细化"},
		{"id":"f97ef2b236dddf75","fromNode":"exporter-containers","fromSide":"bottom","toNode":"dashboard-actor","toSide":"bottom","color":"3"},
		{"id":"8ea4fa6add7df724","fromNode":"actor-lifecycle","fromSide":"right","toNode":"kubecontroller-overview","toSide":"left"},
		{"id":"edge-exporter-config-task","fromNode":"63020bf5856229b9","fromSide":"right","toNode":"exporter-config-task","toSide":"left","label":"spawn"},
		{"id":"edge-exporter-metrics-task","fromNode":"63020bf5856229b9","fromSide":"right","toNode":"exporter-metrics-task","toSide":"left","label":"spawn"},
		{"id":"edge-theproxy-alive","fromNode":"63a7919ba26e1c77","fromSide":"right","toNode":"the-proxy-alive-task","toSide":"left","color":"2","label":"tokio::spawn"},
		{"id":"edge-theproxy-keepalive","fromNode":"63a7919ba26e1c77","fromSide":"right","toNode":"the-proxy-keepalive-task","toSide":"left","color":"2","label":"tokio::spawn"},
		{"id":"edge-service-agent-docker","fromNode":"service-agent-summary","fromSide":"right","toNode":"docker-ops-module","toSide":"left","label":"容器创建/监护调用"},
		{"id":"edge-kubecontroller-docker","fromNode":"kubecontroller-overview","fromSide":"top","toNode":"docker-ops-module","toSide":"left","label":"容器回收/重建"},
		{"id":"7b9668e7efde71dc","fromNode":"kubecontroller-overview","fromSide":"bottom","toNode":"kubecontroller-actor-scan-task","toSide":"top"},
		{"id":"9a551488e256a9de","fromNode":"actor-lifecycle","fromSide":"right","toNode":"root-actor-definition","toSide":"left"},
		{"id":"54525a6e199bb46a","fromNode":"log-collector-overview","fromSide":"top","toNode":"logcollector-kubecontroller-link","toSide":"bottom"},
		{"id":"81d720be0498e0fd","fromNode":"63020bf5856229b9","fromSide":"top","toNode":"block-exporter-vs-kube","toSide":"left"},
		{"id":"edge-logcollector-kubecontroller","fromNode":"logcollector-kubecontroller-link","fromSide":"top","toNode":"kubecontroller-overview","toSide":"right","color":"2","label":"容器事件总线"},
		{"id":"edge-exporter-kubecontroller","fromNode":"block-exporter-vs-kube","fromSide":"top","toNode":"kubecontroller-overview","toSide":"right","color":"2","label":"容器事件总线"},
		{"id":"49ce80a579bad890","fromNode":"actor-lifecycle","fromSide":"right","toNode":"actor-fullpath","toSide":"left"},
		{"id":"0232ebc7ed40b630","fromNode":"9cf4ae7f0bc843ff","fromSide":"right","toNode":"bb8189dc5a9eeffb","toSide":"left","label":"Root 聚合"},
		{"id":"a74394940aa58da8","fromNode":"9cf4ae7f0bc843ff","fromSide":"right","toNode":"2b2c75cfe9dfdc26","toSide":"left","label":"CPU 曲线"},
		{"id":"385a49ab86129d32","fromNode":"aae4556fb8648bc3","fromSide":"right","toNode":"d33f4f3976ad1ed5","toSide":"left","color":"2","label":"Pod 占用"},
		{"id":"36567c1d2e5f64df","fromNode":"aae4556fb8648bc3","fromSide":"right","toNode":"05a61dd0441d01bf","toSide":"left","color":"2","label":"Container 明细"},
		{"id":"04dc802abdac9f56","fromNode":"5335dde14d1038ab","fromSide":"left","toNode":"05a61dd0441d01bf","toSide":"right"},
		{"id":"10720492ad611278","fromNode":"aae4556fb8648bc3","fromSide":"right","toNode":"18146762550f3fd1","toSide":"left","color":"2","label":"节点内存"},
		{"id":"6db15c0404bcf855","fromNode":"6dd5a77cb7493db1","fromSide":"right","toNode":"18146762550f3fd1","toSide":"left","label":"Other"},
		{"id":"837c7a4421096814","fromNode":"be26e494f4ce5f63","fromSide":"right","toNode":"18146762550f3fd1","toSide":"left","color":"4","label":"Free"},
		{"id":"c03dfc9025b645b8","fromNode":"9637b6dd8a712c9e","fromSide":"right","toNode":"c0d92205384ae5ff","toSide":"left","label":"活跃筛选"},
		{"id":"d44c0b4fdaba5e92","fromNode":"9637b6dd8a712c9e","fromSide":"top","toNode":"dashboard-actor","toSide":"right","label":"变量依赖"},
		{"id":"aa40ed616a9788a5","fromNode":"aae4556fb8648bc3","fromSide":"right","toNode":"c0d92205384ae5ff","toSide":"left","color":"2","label":"容器数量"},
		{"id":"21de63107ec8aba2","fromNode":"743be6174a9b2798","fromSide":"right","toNode":"cc3c1a31ff6a6d92","toSide":"left","label":"下载速率"},
		{"id":"d174c266194f9e67","fromNode":"a2ec4b6c3481a869","fromSide":"right","toNode":"d8835376af30e59a","toSide":"left","label":"上传速率"},
		{"id":"6feb4b3f1510e3cb","fromNode":"ea2e9375f8de9b78","fromSide":"right","toNode":"1cab9152c78575fa","toSide":"left","label":"CPU 堆叠"},
		{"id":"6bef20700182b67c","fromNode":"ea2e9375f8de9b78","fromSide":"right","toNode":"8ecf221a16634edd","toSide":"left","label":"节点 CPU"},
		{"id":"ec27c1c2a487d2ee","fromNode":"aae4556fb8648bc3","fromSide":"right","toNode":"a1985af03c62db31","toSide":"left","color":"2","label":"内存曲线"},
		{"id":"530cb48e6e1016ae","fromNode":"aae4556fb8648bc3","fromSide":"right","toNode":"2faefa3b8c902c4d","toSide":"left","color":"2","label":"容器内存"},
		{"id":"cf1aac4f5faa7729","fromNode":"6dd5a77cb7493db1","fromSide":"right","toNode":"a1985af03c62db31","toSide":"left","label":"非容器内存"},
		{"id":"0a8c07f2d3aa3816","fromNode":"6dd5a77cb7493db1","fromSide":"right","toNode":"2faefa3b8c902c4d","toSide":"left","label":"Other"},
		{"id":"2098c461a939ed96","fromNode":"02e699f71e2275ad","fromSide":"right","toNode":"a1985af03c62db31","toSide":"left","color":"6","label":"内存曲线"},
		{"id":"5381671fa740a1c2","fromNode":"4e81f771478c5049","fromSide":"right","toNode":"a1985af03c62db31","toSide":"left","color":"6","label":"总量基线"},
		{"id":"aaffdfe2e7cc99ae","fromNode":"be26e494f4ce5f63","fromSide":"right","toNode":"a1985af03c62db31","toSide":"left","color":"4","label":"剩余内存"},
		{"id":"3680a5c80722a0ac","fromNode":"be26e494f4ce5f63","fromSide":"right","toNode":"2faefa3b8c902c4d","toSide":"left","color":"4","label":"Free"},
		{"id":"edge-import-to-shared","fromNode":"grafana-import-flow","fromSide":"right","toNode":"grafana-shared-module","toSide":"left","label":"使用共享模板"},
		{"id":"edge-general-grafana-import","fromNode":"grafana-manager-general","fromSide":"right","toNode":"grafana-import-flow","toSide":"left","label":"调用共享模板 + HTTP 导入"},
		{"id":"edge-master-grafana-manager","fromNode":"service-agent-summary","fromSide":"right","toNode":"grafana-manager-general","toSide":"left","label":"master_agent 使用"},
		{"id":"edge-cli-service-bridge","fromNode":"cli-new-or-update","fromSide":"bottom","toNode":"cli-service-status-bridge","toSide":"top","color":"5","label":"deploy version broadcast"},
		{"id":"ef8a39c3d27aa934","fromNode":"service-agent-summary","fromSide":"bottom","toNode":"service-agent-status-sync","toSide":"top"},
		{"id":"f8313667688ba79f","fromNode":"cli-service-status-bridge","fromSide":"bottom","toNode":"service-agent-status-sync","toSide":"right","color":"5"},
		{"id":"edge-startup-grafana","fromNode":"service-agent-status-sync","fromSide":"right","toNode":"service-agent-module-grafana","toSide":"left","label":"startup"},
		{"id":"edge-startup-greptime","fromNode":"service-agent-status-sync","fromSide":"right","toNode":"service-agent-module-greptime","toSide":"left","label":"startup"}
	]
}
